{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "# Batch Normalization\n",
    "One way to make deep networks easier to train is to use more sophisticated optimization procedures such as SGD+momentum, RMSProp, or Adam. Another strategy is to change the architecture of the network to make it easier to train. \n",
    "One idea along these lines is batch normalization which was proposed by [1] in 2015.\n",
    "\n",
    "The idea is relatively straightforward. Machine learning methods tend to work better when their input data consists of uncorrelated features with zero mean and unit variance. When training a neural network, we can preprocess the data before feeding it to the network to explicitly decorrelate its features; this will ensure that the first layer of the network sees data that follows a nice distribution. However, even if we preprocess the input data, the activations at deeper layers of the network will likely no longer be decorrelated and will no longer have zero mean or unit variance since they are output from earlier layers in the network. Even worse, during the training process the distribution of features at each layer of the network will shift as the weights of each layer are updated.\n",
    "\n",
    "The authors of [1] hypothesize that the shifting distribution of features inside deep neural networks may make training deep networks more difficult. To overcome this problem, [1] proposes to insert batch normalization layers into the network. At training time, a batch normalization layer uses a minibatch of data to estimate the mean and standard deviation of each feature. These estimated means and standard deviations are then used to center and normalize the features of the minibatch. A running average of these means and standard deviations is kept during training, and at test time these running averages are used to center and normalize features.\n",
    "\n",
    "It is possible that this normalization strategy could reduce the representational power of the network, since it may sometimes be optimal for certain layers to have features that are not zero-mean or unit variance. To this end, the batch normalization layer includes learnable shift and scale parameters for each feature dimension.\n",
    "\n",
    "[1] [Sergey Ioffe and Christian Szegedy, \"Batch Normalization: Accelerating Deep Network Training by Reducing\n",
    "Internal Covariate Shift\", ICML 2015.](https://arxiv.org/abs/1502.03167)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# As usual, a bit of setup\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cs231n.classifiers.fc_net import *\n",
    "from cs231n.layers import *\n",
    "from cs231n.data_utils import get_CIFAR10_data\n",
    "from cs231n.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from cs231n.solver import Solver\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "def print_mean_std(x,axis=0):\n",
    "    print('  means: ', x.mean(axis=axis))\n",
    "    print('  stds:  ', x.std(axis=axis))\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (49000, 3, 32, 32)\n",
      "y_train:  (49000,)\n",
      "X_val:  (1000, 3, 32, 32)\n",
      "y_val:  (1000,)\n",
      "X_test:  (1000, 3, 32, 32)\n",
      "y_test:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the (preprocessed) CIFAR10 data.\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in data.items():\n",
    "  print('%s: ' % k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch normalization: forward\n",
    "In the file `cs231n/layers.py`, implement the batch normalization forward pass in the function `batchnorm_forward`. Once you have done so, run the following to test your implementation.\n",
    "\n",
    "Referencing the paper linked to above in [1] may be helpful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before batch normalization:\n",
      "  means:  [ -2.3814598  -13.18038246   1.91780462]\n",
      "  stds:   [27.18502186 34.21455511 37.68611762]\n",
      "\n",
      "After batch normalization (gamma=1, beta=0)\n",
      "  means:  [5.99520433e-17 6.93889390e-17 4.10782519e-17]\n",
      "  stds:   [0.99999999 1.         1.        ]\n",
      "\n",
      "After batch normalization (gamma= [1. 2. 3.] , beta= [11. 12. 13.] )\n",
      "  means:  [11. 12. 13.]\n",
      "  stds:   [0.99999999 1.99999999 2.99999999]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the training-time forward pass by checking means and variances\n",
    "# of features both before and after batch normalization   \n",
    "\n",
    "# Simulate the forward pass for a two-layer network\n",
    "np.random.seed(231)\n",
    "N, D1, D2, D3 = 200, 50, 60, 3\n",
    "X = np.random.randn(N, D1)\n",
    "W1 = np.random.randn(D1, D2)\n",
    "W2 = np.random.randn(D2, D3)\n",
    "a = np.maximum(0, X.dot(W1)).dot(W2)\n",
    "\n",
    "print('Before batch normalization:')\n",
    "print_mean_std(a,axis=0)\n",
    "\n",
    "gamma = np.ones((D3,))\n",
    "beta = np.zeros((D3,))\n",
    "# Means should be close to zero and stds close to one\n",
    "print('After batch normalization (gamma=1, beta=0)')\n",
    "a_norm, _ = batchnorm_forward(a, gamma, beta, {'mode': 'train'})\n",
    "print_mean_std(a_norm,axis=0)\n",
    "\n",
    "gamma = np.asarray([1.0, 2.0, 3.0])\n",
    "beta = np.asarray([11.0, 12.0, 13.0])\n",
    "# Now means should be close to beta and stds close to gamma\n",
    "print('After batch normalization (gamma=', gamma, ', beta=', beta, ')')\n",
    "a_norm, _ = batchnorm_forward(a, gamma, beta, {'mode': 'train'})\n",
    "print_mean_std(a_norm,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After batch normalization (test-time):\n",
      "  means:  [-0.03927354 -0.04349152 -0.10452688]\n",
      "  stds:   [1.01531428 1.01238373 0.97819988]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the test-time forward pass by running the training-time\n",
    "# forward pass many times to warm up the running averages, and then\n",
    "# checking the means and variances of activations after a test-time\n",
    "# forward pass.\n",
    "\n",
    "np.random.seed(231)\n",
    "N, D1, D2, D3 = 200, 50, 60, 3\n",
    "W1 = np.random.randn(D1, D2)\n",
    "W2 = np.random.randn(D2, D3)\n",
    "\n",
    "bn_param = {'mode': 'train'}\n",
    "gamma = np.ones(D3)\n",
    "beta = np.zeros(D3)\n",
    "\n",
    "for t in range(50):\n",
    "  X = np.random.randn(N, D1)\n",
    "  a = np.maximum(0, X.dot(W1)).dot(W2)\n",
    "  batchnorm_forward(a, gamma, beta, bn_param)\n",
    "\n",
    "bn_param['mode'] = 'test'\n",
    "X = np.random.randn(N, D1)\n",
    "a = np.maximum(0, X.dot(W1)).dot(W2)\n",
    "a_norm, _ = batchnorm_forward(a, gamma, beta, bn_param)\n",
    "\n",
    "# Means should be close to zero and stds close to one, but will be\n",
    "# noisier than training-time forward passes.\n",
    "print('After batch normalization (test-time):')\n",
    "print_mean_std(a_norm,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch normalization: backward\n",
    "Now implement the backward pass for batch normalization in the function `batchnorm_backward`.\n",
    "\n",
    "To derive the backward pass you should write out the computation graph for batch normalization and backprop through each of the intermediate nodes. Some intermediates may have multiple outgoing branches; make sure to sum gradients across these branches in the backward pass.\n",
    "\n",
    "Once you have finished, run the following to numerically check your backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx error:  1.6674604875341426e-09\n",
      "dgamma error:  7.417225040694815e-13\n",
      "dbeta error:  2.379446949959628e-12\n"
     ]
    }
   ],
   "source": [
    "# Gradient check batchnorm backward pass\n",
    "np.random.seed(231)\n",
    "N, D = 4, 5\n",
    "x = 5 * np.random.randn(N, D) + 12\n",
    "gamma = np.random.randn(D)\n",
    "beta = np.random.randn(D)\n",
    "dout = np.random.randn(N, D)\n",
    "\n",
    "bn_param = {'mode': 'train'}\n",
    "fx = lambda x: batchnorm_forward(x, gamma, beta, bn_param)[0]\n",
    "fg = lambda a: batchnorm_forward(x, a, beta, bn_param)[0]\n",
    "fb = lambda b: batchnorm_forward(x, gamma, b, bn_param)[0]\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dout)\n",
    "da_num = eval_numerical_gradient_array(fg, gamma.copy(), dout)\n",
    "db_num = eval_numerical_gradient_array(fb, beta.copy(), dout)\n",
    "\n",
    "\n",
    "_, cache = batchnorm_forward(x, gamma, beta, bn_param)\n",
    "dx, dgamma, dbeta = batchnorm_backward(dout, cache)\n",
    "\n",
    "#print(\"dx\", dx)\n",
    "#print(\"dx_num\", dx_num)\n",
    "\n",
    "#You should expect to see relative errors between 1e-13 and 1e-8\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dgamma error: ', rel_error(da_num, dgamma))\n",
    "print('dbeta error: ', rel_error(db_num, dbeta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch normalization: alternative backward\n",
    "In class we talked about two different implementations for the sigmoid backward pass. One strategy is to write out a computation graph composed of simple operations and backprop through all intermediate values. Another strategy is to work out the derivatives on paper. For example, you can derive a very simple formula for the sigmoid function's backward pass by simplifying gradients on paper.\n",
    "\n",
    "Surprisingly, it turns out that you can do a similar simplification for the batch normalization backward pass too!  \n",
    "\n",
    "In the forward pass, given a set of inputs $X=\\begin{bmatrix}x_1\\\\x_2\\\\...\\\\x_N\\end{bmatrix}$, \n",
    "\n",
    "we first calculate the mean $\\mu$ and variance $v$.\n",
    "With $\\mu$ and $v$ calculated, we can calculate the standard deviation $\\sigma$  and normalized data $Y$.\n",
    "The equations and graph illustration below describe the computation ($y_i$ is the i-th element of the vector $Y$).\n",
    "\n",
    "\\begin{align}\n",
    "& \\mu=\\frac{1}{N}\\sum_{k=1}^N x_k  &  v=\\frac{1}{N}\\sum_{k=1}^N (x_k-\\mu)^2 \\\\\n",
    "& \\sigma=\\sqrt{v+\\epsilon}         &  y_i=\\frac{x_i-\\mu}{\\sigma}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"notebook_images/batchnorm_graph.png\" width=691 height=202>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "source": [
    "The meat of our problem during backpropagation is to compute $\\frac{\\partial L}{\\partial X}$, given the upstream gradient we receive, $\\frac{\\partial L}{\\partial Y}.$ To do this, recall the chain rule in calculus gives us $\\frac{\\partial L}{\\partial X} = \\frac{\\partial L}{\\partial Y} \\cdot \\frac{\\partial Y}{\\partial X}$.\n",
    "\n",
    "The unknown/hart part is $\\frac{\\partial Y}{\\partial X}$. We can find this by first deriving step-by-step our local gradients at \n",
    "$\\frac{\\partial v}{\\partial X}$, $\\frac{\\partial \\mu}{\\partial X}$,\n",
    "$\\frac{\\partial \\sigma}{\\partial v}$, \n",
    "$\\frac{\\partial Y}{\\partial \\sigma}$, and $\\frac{\\partial Y}{\\partial \\mu}$,\n",
    "and then use the chain rule to compose these gradients (which appear in the form of vectors!) appropriately to compute $\\frac{\\partial Y}{\\partial X}$.\n",
    "\n",
    "If it's challenging to directly reason about the gradients over $X$ and $Y$ which require matrix multiplication, try reasoning about the gradients in terms of individual elements $x_i$ and $y_i$ first: in that case, you will need to come up with the derivations for $\\frac{\\partial L}{\\partial x_i}$, by relying on the Chain Rule to first calculate the intermediate $\\frac{\\partial \\mu}{\\partial x_i}, \\frac{\\partial v}{\\partial x_i}, \\frac{\\partial \\sigma}{\\partial x_i},$ then assemble these pieces to calculate $\\frac{\\partial y_i}{\\partial x_i}$. \n",
    "\n",
    "You should make sure each of the intermediary gradient derivations are all as simplified as possible, for ease of implementation. \n",
    "\n",
    "After doing so, implement the simplified batch normalization backward pass in the function `batchnorm_backward_alt` and compare the two implementations by running the following. Your two implementations should compute nearly identical results, but the alternative implementation should be a bit faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx difference:  1.1507791538531613e-11\n",
      "dgamma difference:  0.0\n",
      "dbeta difference:  0.0\n",
      "speedup: 1.77x\n"
     ]
    }
   ],
   "source": [
    "N, D = 100, 500\n",
    "x = 5 * np.random.randn(N, D) + 12\n",
    "gamma = np.random.randn(D)\n",
    "beta = np.random.randn(D)\n",
    "dout = np.random.randn(N, D)\n",
    "\n",
    "bn_param = {'mode': 'train'}\n",
    "out, cache = batchnorm_forward(x, gamma, beta, bn_param)\n",
    "\n",
    "t1 = time.time()\n",
    "dx1, dgamma1, dbeta1 = batchnorm_backward(dout, cache)\n",
    "t2 = time.time()\n",
    "dx2, dgamma2, dbeta2 = batchnorm_backward_alt(dout, cache)\n",
    "t3 = time.time()\n",
    "\n",
    "print('dx difference: ', rel_error(dx1, dx2))\n",
    "print('dgamma difference: ', rel_error(dgamma1, dgamma2))\n",
    "print('dbeta difference: ', rel_error(dbeta1, dbeta2))\n",
    "print('speedup: %.2fx' % ((t2 - t1) / (t3 - t2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Nets with Batch Normalization\n",
    "Now that you have a working implementation for batch normalization, go back to your `FullyConnectedNet` in the file `cs231n/classifiers/fc_net.py`. Modify your implementation to add batch normalization.\n",
    "\n",
    "Concretely, when the `normalization` flag is set to `\"batchnorm\"` in the constructor, you should insert a batch normalization layer before each ReLU nonlinearity. The outputs from the last layer of the network should not be normalized. Once you are done, run the following to gradient-check your implementation.\n",
    "\n",
    "HINT: You might find it useful to define an additional helper layer similar to those in the file `cs231n/layer_utils.py`. If you decide to do so, do it in the file `cs231n/classifiers/fc_net.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running check with reg =  0\n",
      "Initial loss:  2.2861785657847262\n",
      "(0, 0) 0.14081218036032794\n",
      "(0, 1) 0.00011360896667866881\n",
      "(0, 2) -0.0001054600851091436\n",
      "(0, 3) 7.23847648487208e-06\n",
      "(0, 4) 3.784528246342233e-07\n",
      "(0, 5) 6.837752586363876e-06\n",
      "(0, 6) -1.0688316898210813e-05\n",
      "(0, 7) 4.694893362966467e-05\n",
      "(0, 8) -1.7397860929690976e-06\n",
      "(0, 9) 0.00013254615183200258\n",
      "(0, 10) 9.21414056165304e-06\n",
      "(0, 11) -1.5844126011188564e-05\n",
      "(0, 12) -2.6600499580808896e-06\n",
      "(0, 13) 2.6660451624138655e-06\n",
      "(0, 14) -1.572186825171684e-06\n",
      "(0, 15) -5.557110327458758e-06\n",
      "(0, 16) 2.526183706663687e-05\n",
      "(0, 17) -0.04468903056498163\n",
      "(0, 18) -3.224107647525898e-05\n",
      "(0, 19) 1.380517922200397e-06\n",
      "(1, 0) -2.0390591325636365\n",
      "(1, 1) -0.0016451147777374329\n",
      "(1, 2) 0.0015271150122231345\n",
      "(1, 3) -0.0001048167774797548\n",
      "(1, 4) -5.480083054010264e-06\n",
      "(1, 5) -9.901395259248601e-05\n",
      "(1, 6) 0.00015477206183334147\n",
      "(1, 7) -0.0006798441365418738\n",
      "(1, 8) 2.5193136465873064e-05\n",
      "(1, 9) -0.0019193345135448678\n",
      "(1, 10) -0.00013342553728534767\n",
      "(1, 11) 0.0002294310963435464\n",
      "(1, 12) 3.851914343044882e-05\n",
      "(1, 13) -3.8605496577304166e-05\n",
      "(1, 14) 2.27661001162005e-05\n",
      "(1, 15) 8.046974198094858e-05\n",
      "(1, 16) -0.0003658042979637343\n",
      "(1, 17) 0.6470951853465579\n",
      "(1, 18) 0.00046686661203665375\n",
      "(1, 19) -1.999032051003269e-05\n",
      "(2, 0) 3.530626642689327\n",
      "(2, 1) 0.0028484339997802972\n",
      "(2, 2) -0.002644123897610484\n",
      "(2, 3) 0.0001814849603931634\n",
      "(2, 4) 9.488498875498408e-06\n",
      "(2, 5) 0.00017143768626937114\n",
      "(2, 6) -0.0002679800381599762\n",
      "(2, 7) 0.0011771158714424246\n",
      "(2, 8) -4.3620662637522394e-05\n",
      "(2, 9) 0.003323232089513794\n",
      "(2, 10) 0.00023101962565164055\n",
      "(2, 11) -0.0003972483675340754\n",
      "(2, 12) -6.66939392601762e-05\n",
      "(2, 13) 6.684346409713271e-05\n",
      "(2, 14) -3.9418313058092735e-05\n",
      "(2, 15) -0.0001393292814455549\n",
      "(2, 16) 0.0006333717106343784\n",
      "(2, 17) -1.1203281331084725\n",
      "(2, 18) -0.0008083560043559145\n",
      "(2, 19) 3.461222419787191e-05\n",
      "(3, 0) 1.0995847431249928\n",
      "(3, 1) 0.0008871546830491183\n",
      "(3, 2) -0.0008235213400098472\n",
      "(3, 3) 5.65241631278468e-05\n",
      "(3, 4) 2.9552360558682263e-06\n",
      "(3, 5) 5.339488851063833e-05\n",
      "(3, 6) -8.346332514008735e-05\n",
      "(3, 7) 0.00036661695901329944\n",
      "(3, 8) -1.3585821356798531e-05\n",
      "(3, 9) 0.0010350320600593932\n",
      "(3, 10) 7.195191109587995e-05\n",
      "(3, 11) -0.00012372440849617306\n",
      "(3, 12) -2.077205074613175e-05\n",
      "(3, 13) 2.0818657908705515e-05\n",
      "(3, 14) -1.2276979433067934e-05\n",
      "(3, 15) -4.339462122970871e-05\n",
      "(3, 16) 0.0001972658925097903\n",
      "(3, 17) -0.34896589831134855\n",
      "(3, 18) -0.0002517653641120887\n",
      "(3, 19) 1.0780132342347313e-05\n",
      "(4, 0) 1.40645176427423\n",
      "(4, 1) 0.0011347347950163567\n",
      "(4, 2) -0.0010533432126536013\n",
      "(4, 3) 7.229847831524694e-05\n",
      "(4, 4) 3.7799541274807775e-06\n",
      "(4, 5) 6.829585785794734e-05\n",
      "(4, 6) -0.0001067556043565787\n",
      "(4, 7) 0.00046892949523424926\n",
      "(4, 8) -1.7377232985893443e-05\n",
      "(4, 9) 0.001323880671755262\n",
      "(4, 10) 9.203162676385544e-05\n",
      "(4, 11) -0.00015825247778877838\n",
      "(4, 12) -2.6568969246909543e-05\n",
      "(4, 13) 2.662854381441093e-05\n",
      "(4, 14) -1.570312768706117e-05\n",
      "(4, 15) -5.550484516447795e-05\n",
      "(4, 16) 0.00025231730038655087\n",
      "(4, 17) -0.4463494148509994\n",
      "(4, 18) -0.0003220260502700967\n",
      "(4, 19) 1.3788525876634592e-05\n",
      "(5, 0) 1.0690875629659757\n",
      "(5, 1) 0.0008625494762881657\n",
      "(5, 2) -0.0008006810547911413\n",
      "(5, 3) 5.49564616036946e-05\n",
      "(5, 4) 2.873234983269412e-06\n",
      "(5, 5) 5.191398422255133e-05\n",
      "(5, 6) -8.114848792928342e-05\n",
      "(5, 7) 0.000356448848215507\n",
      "(5, 8) -1.320898945778026e-05\n",
      "(5, 9) 0.0010063254896053309\n",
      "(5, 10) 6.995630741357672e-05\n",
      "(5, 11) -0.00012029293117166161\n",
      "(5, 12) -2.019595601865376e-05\n",
      "(5, 13) 2.0241230913597974e-05\n",
      "(5, 14) -1.1936451826954906e-05\n",
      "(5, 15) -4.2191072857633565e-05\n",
      "(5, 16) 0.00019179471344443752\n",
      "(5, 17) -0.3392875457253197\n",
      "(5, 18) -0.0002447826608076298\n",
      "(5, 19) 1.0481127077355266e-05\n",
      "(6, 0) 0.5434983438412644\n",
      "(6, 1) 0.00043850059139316494\n",
      "(6, 2) -0.0004070480841278367\n",
      "(6, 3) 2.7938629187929106e-05\n",
      "(6, 4) 1.4606982290388257e-06\n",
      "(6, 5) 2.639188867448183e-05\n",
      "(6, 6) -4.125404462484994e-05\n",
      "(6, 7) 0.00018121051326147605\n",
      "(6, 8) -6.715161759984766e-06\n",
      "(6, 9) 0.0005115930346022424\n",
      "(6, 10) 3.5564173828106505e-05\n",
      "(6, 11) -6.115419282082257e-05\n",
      "(6, 12) -1.0267164896049508e-05\n",
      "(6, 13) 1.0290168717119741e-05\n",
      "(6, 14) -6.06825700799618e-06\n",
      "(6, 15) -2.14489759287062e-05\n",
      "(6, 16) 9.750409368791678e-05\n",
      "(6, 17) -0.17248742798514624\n",
      "(6, 18) -0.00012444196784144879\n",
      "(6, 19) 5.328337771004498e-06\n",
      "(7, 0) -2.2677904481849254\n",
      "(7, 1) -0.0018296493875524786\n",
      "(7, 2) 0.0016984134987296782\n",
      "(7, 3) -0.00011657423915067965\n",
      "(7, 4) -6.094835747205706e-06\n",
      "(7, 5) -0.00011012049050407312\n",
      "(7, 6) 0.00017213301894969388\n",
      "(7, 7) -0.0007561030912484056\n",
      "(7, 8) 2.801912035721443e-05\n",
      "(7, 9) -0.0021346287848444945\n",
      "(7, 10) -0.00014839209860895153\n",
      "(7, 11) 0.00025516664337033035\n",
      "(7, 12) 4.2839864988764014e-05\n",
      "(7, 13) -4.293592148485458e-05\n",
      "(7, 14) 2.53197907085223e-05\n",
      "(7, 15) 8.94961438291375e-05\n",
      "(7, 16) -0.0004068370307308555\n",
      "(7, 17) 0.7196742200177296\n",
      "(7, 18) 0.0005192356100636175\n",
      "(7, 19) -2.2232660157328606e-05\n",
      "(8, 0) 3.070184493969563\n",
      "(8, 1) 0.0024769842177363444\n",
      "(8, 2) -0.002299316959053499\n",
      "(8, 3) 0.0001578184694039919\n",
      "(8, 4) 8.251155314553671e-06\n",
      "(8, 5) 0.0001490813694715598\n",
      "(8, 6) -0.0002330341475342834\n",
      "(8, 7) 0.0010236142156117012\n",
      "(8, 8) -3.793232394855295e-05\n",
      "(8, 9) 0.002889866212996139\n",
      "(8, 10) 0.000200893546242753\n",
      "(8, 11) -0.00034544522797830263\n",
      "(8, 12) -5.799671853878862e-05\n",
      "(8, 13) 5.8126792268353704e-05\n",
      "(8, 14) -3.427798045407826e-05\n",
      "(8, 15) -0.00012116008196727533\n",
      "(8, 16) 0.0005507769351709157\n",
      "(8, 17) -0.9742588262362516\n",
      "(8, 18) -0.0007029424597959632\n",
      "(8, 19) 3.0098612491258333e-05\n",
      "(9, 0) 0.8025965218649843\n",
      "(9, 1) 0.0006475431746366667\n",
      "(9, 2) -0.0006010965503122634\n",
      "(9, 3) 4.1257552929607755e-05\n",
      "(9, 4) 2.157074519004709e-06\n",
      "(9, 5) 3.897346889658593e-05\n",
      "(9, 6) -6.092073512320439e-05\n",
      "(9, 7) 0.00026759741089676936\n",
      "(9, 8) -9.916423238109928e-06\n",
      "(9, 9) 0.0007554803893583538\n",
      "(9, 10) 5.251838963715726e-05\n",
      "(9, 11) -9.030771686013848e-05\n",
      "(9, 12) -1.5161738531332956e-05\n",
      "(9, 13) 1.5195733560346978e-05\n",
      "(9, 14) -8.961076325419981e-06\n",
      "(9, 15) -3.167415218996439e-05\n",
      "(9, 16) 0.00014398637837587103\n",
      "(9, 17) -0.25471505207264045\n",
      "(9, 18) -0.0001837661134374002\n",
      "(9, 19) 7.868528051346857e-06\n",
      "(10, 0) -0.6003910723251238\n",
      "(10, 1) -0.00048440218503031923\n",
      "(10, 2) 0.00044965724477208363\n",
      "(10, 3) -3.086320088385719e-05\n",
      "(10, 4) -1.6135981439902023e-06\n",
      "(10, 5) -2.9154545444498577e-05\n",
      "(10, 6) 4.5572479123734404e-05\n",
      "(10, 7) -0.00020017936197547212\n",
      "(10, 8) 7.418088365795938e-06\n",
      "(10, 9) -0.0005651458634403639\n",
      "(10, 10) -3.928699587874007e-05\n",
      "(10, 11) 6.755573878081123e-05\n",
      "(10, 12) 1.1341905192807643e-05\n",
      "(10, 13) -1.1367351504532051e-05\n",
      "(10, 14) 6.703437804844724e-06\n",
      "(10, 15) 2.3694246564787132e-05\n",
      "(10, 16) -0.00010771068481574274\n",
      "(10, 17) 0.19054304241095107\n",
      "(10, 18) 0.0001374683700205992\n",
      "(10, 19) -5.886113818576177e-06\n",
      "(11, 0) -0.2307930069056496\n",
      "(11, 1) -0.00018620656128121024\n",
      "(11, 2) 0.00017285044506820665\n",
      "(11, 3) -1.1863976467907376e-05\n",
      "(11, 4) -6.203038083185675e-07\n",
      "(11, 5) -1.1207146322078641e-05\n",
      "(11, 6) 1.7518275718941823e-05\n",
      "(11, 7) -7.694991310813748e-05\n",
      "(11, 8) 2.8515412253682366e-06\n",
      "(11, 9) -0.00021724482213159033\n",
      "(11, 10) -1.5102119554910585e-05\n",
      "(11, 11) 2.5968738270876198e-05\n",
      "(11, 12) 4.359868022163482e-06\n",
      "(11, 13) -4.369704598161661e-06\n",
      "(11, 14) 2.5768276401549883e-06\n",
      "(11, 15) 9.108180876182814e-06\n",
      "(11, 16) -4.140452425360763e-05\n",
      "(11, 17) 0.07324587563140028\n",
      "(11, 18) 5.2843507347688494e-05\n",
      "(11, 19) -2.262678933107054e-06\n",
      "(12, 0) 0.23822250401206443\n",
      "(12, 1) 0.00019220074420900343\n",
      "(12, 2) -0.0001784146830274835\n",
      "(12, 3) 1.224589318837843e-05\n",
      "(12, 4) 6.402434138408353e-07\n",
      "(12, 5) 1.156790219170034e-05\n",
      "(12, 6) -1.8082224606530417e-05\n",
      "(12, 7) 7.942702051622064e-05\n",
      "(12, 8) -2.943356669504737e-06\n",
      "(12, 9) 0.00022423820578154616\n",
      "(12, 10) 1.5588286217393943e-05\n",
      "(12, 11) -2.680473620841894e-05\n",
      "(12, 12) -4.500244621397087e-06\n",
      "(12, 13) 4.5103254464606835e-06\n",
      "(12, 14) -2.659805709015472e-06\n",
      "(12, 15) -9.401368572525826e-06\n",
      "(12, 16) 4.273736919913062e-05\n",
      "(12, 17) -0.07560374282178373\n",
      "(12, 18) -5.454459106601916e-05\n",
      "(12, 19) 2.3355095635224643e-06\n",
      "(13, 0) -0.9012996448731768\n",
      "(13, 1) -0.0007271774737915847\n",
      "(13, 2) 0.000675018885232248\n",
      "(13, 3) -4.6331383174447176e-05\n",
      "(13, 4) -2.422306799587659e-06\n",
      "(13, 5) -4.37663683072742e-05\n",
      "(13, 6) 6.841271993351938e-05\n",
      "(13, 7) -0.00030050628652134037\n",
      "(13, 8) 1.1135914412818691e-05\n",
      "(13, 9) -0.0008483887370402953\n",
      "(13, 10) -5.897708987845362e-05\n",
      "(13, 11) 0.0001014136330468318\n",
      "(13, 12) 1.7026313692269923e-05\n",
      "(13, 13) -1.7064483159856536e-05\n",
      "(13, 14) 1.0063105904123404e-05\n",
      "(13, 15) 3.556943628524323e-05\n",
      "(13, 16) -0.00016169368066698553\n",
      "(13, 17) 0.2860392479542284\n",
      "(13, 18) 0.00020636545805530202\n",
      "(13, 19) -8.836154030689158e-06\n",
      "(14, 0) -1.3138567402481982\n",
      "(14, 1) -0.0010600293975926434\n",
      "(14, 2) 0.0009839962178403994\n",
      "(14, 3) -6.753868575515298e-05\n",
      "(14, 4) -3.531108738741295e-06\n",
      "(14, 5) -6.37996322438994e-05\n",
      "(14, 6) 9.972735970364964e-05\n",
      "(14, 7) -0.00043805745697511606\n",
      "(14, 8) 1.6233214772398696e-05\n",
      "(14, 9) -0.001236722835251669\n",
      "(14, 10) -8.59727178337266e-05\n",
      "(14, 11) 0.0001478338562677095\n",
      "(14, 12) 2.481974625823113e-05\n",
      "(14, 13) -2.4875479454067314e-05\n",
      "(14, 14) 1.4669332415451207e-05\n",
      "(14, 15) 5.185065710122671e-05\n",
      "(14, 16) -0.00023570594365196482\n",
      "(14, 17) 0.41696490433729133\n",
      "(14, 18) 0.0003008254312319991\n",
      "(14, 19) -1.288076312278008e-05\n",
      "W1 relative error: 1.00e+00\n",
      "(0, 0) 0.000648578746265116\n",
      "(0, 1) -0.00035679221799256306\n",
      "(0, 2) -0.00010731051602874685\n",
      "(0, 3) 5.50204326543735e-06\n",
      "(0, 4) 5.014388904100997e-06\n",
      "(0, 5) 1.878674993349705e-05\n",
      "(0, 6) -1.4471801534909899e-05\n",
      "(0, 7) -0.0006214199821386046\n",
      "(0, 8) -0.00012389893555564413\n",
      "(0, 9) 0.13938181244732561\n",
      "(0, 10) 7.011502489717713e-06\n",
      "(0, 11) -1.316675657392352e-05\n",
      "(0, 12) -1.2740919430598296e-06\n",
      "(0, 13) -4.6733061864756564e-06\n",
      "(0, 14) -0.01234063504718108\n",
      "(0, 15) 0.00016295249594122652\n",
      "(0, 16) -3.3191671633403526e-06\n",
      "(0, 17) -0.0045040668084084245\n",
      "(0, 18) 5.52138335052632e-06\n",
      "(0, 19) -1.3540324417249392e-05\n",
      "(0, 20) -0.0002765938589277539\n",
      "(0, 21) 7.439189264601964e-05\n",
      "(0, 22) -1.9219803526482337e-05\n",
      "(0, 23) -0.005582631934508696\n",
      "(0, 24) 2.8351276881721784e-05\n",
      "(0, 25) -1.4018586291797417e-05\n",
      "(0, 26) -4.555238408698869e-05\n",
      "(0, 27) 4.54140280936599e-05\n",
      "(0, 28) -0.0001546632377724677\n",
      "(0, 29) 5.750000475757132e-06\n",
      "(1, 0) -0.0011504364350045648\n",
      "(1, 1) 0.0006328711332770354\n",
      "(1, 2) 0.00019034531728578938\n",
      "(1, 3) -9.759437702427931e-06\n",
      "(1, 4) -8.894440739481979e-06\n",
      "(1, 5) -3.3323610537649984e-05\n",
      "(1, 6) 2.566979961926563e-05\n",
      "(1, 7) 0.0011022627255385942\n",
      "(1, 8) 0.0002197695359029694\n",
      "(1, 9) -0.2472328608504881\n",
      "(1, 10) -1.2436851548613957e-05\n",
      "(1, 11) 2.3354940204001192e-05\n",
      "(1, 12) 2.259947784466476e-06\n",
      "(1, 13) 8.289369191061269e-06\n",
      "(1, 14) 0.02188958752036285\n",
      "(1, 15) -0.00028904196813783756\n",
      "(1, 16) 5.887490495126712e-06\n",
      "(1, 17) 0.007989226658011717\n",
      "(1, 18) -9.793721389428356e-06\n",
      "(1, 19) 2.4017587918478963e-05\n",
      "(1, 20) 0.000490616858250803\n",
      "(1, 21) -0.0001319549358669292\n",
      "(1, 22) 3.409175164392764e-05\n",
      "(1, 23) 0.009902365949443492\n",
      "(1, 24) -5.0288928576946994e-05\n",
      "(1, 25) 2.4865887127134553e-05\n",
      "(1, 26) 8.07999223084721e-05\n",
      "(1, 27) -8.055454081556945e-05\n",
      "(1, 28) 0.0002743386406933723\n",
      "(1, 29) -1.019924145140294e-05\n",
      "(2, 0) 0.001145078099007435\n",
      "(2, 1) -0.0006299234245332741\n",
      "(2, 2) -0.0001894587597917052\n",
      "(2, 3) 9.71400737626027e-06\n",
      "(2, 4) 8.852985011742476e-06\n",
      "(2, 5) 3.31683569498864e-05\n",
      "(2, 6) -2.55502285995135e-05\n",
      "(2, 7) -0.0010971287434102805\n",
      "(2, 8) -0.00021874591027426502\n",
      "(2, 9) 0.24608133424308673\n",
      "(2, 10) 1.2378897906728524e-05\n",
      "(2, 11) -2.3246138347587927e-05\n",
      "(2, 12) -2.249445074653522e-06\n",
      "(2, 13) -8.250777838725298e-06\n",
      "(2, 14) -0.021787633253111945\n",
      "(2, 15) 0.0002876957116981771\n",
      "(2, 16) -5.86006798641847e-06\n",
      "(2, 17) -0.007952015601553342\n",
      "(2, 18) 9.748113427576754e-06\n",
      "(2, 19) -2.3905721846517732e-05\n",
      "(2, 20) -0.0004883317306081381\n",
      "(2, 21) 0.0001313403164004967\n",
      "(2, 22) -3.393296754694575e-05\n",
      "(2, 23) -0.009856244131967173\n",
      "(2, 24) 5.005469372321158e-05\n",
      "(2, 25) -2.4750068661205656e-05\n",
      "(2, 26) -8.042360111204516e-05\n",
      "(2, 27) 8.017932984216714e-05\n",
      "(2, 28) -0.00027306086280987074\n",
      "(2, 29) 1.0151723905948984e-05\n",
      "(3, 0) 0.0011571670732735129\n",
      "(3, 1) -0.0006365737270641603\n",
      "(3, 2) -0.0001914589153884094\n",
      "(3, 3) 9.816569779275142e-06\n",
      "(3, 4) 8.946487994876406e-06\n",
      "(3, 5) 3.351856570077416e-05\n",
      "(3, 6) -2.581999059003692e-05\n",
      "(3, 7) -0.0011087115447949714\n",
      "(3, 8) -0.0002210553073922483\n",
      "(3, 9) 0.2486793013067867\n",
      "(3, 10) 1.250961556564789e-05\n",
      "(3, 11) -2.3491564249411564e-05\n",
      "(3, 12) -2.2732038473805005e-06\n",
      "(3, 13) -8.33790814169788e-06\n",
      "(3, 14) -0.022017652945294227\n",
      "(3, 15) 0.0002907329932355651\n",
      "(3, 16) -5.921907408890092e-06\n",
      "(3, 17) -0.008035967757891171\n",
      "(3, 18) 9.851008897499014e-06\n",
      "(3, 19) -2.4158097744475523e-05\n",
      "(3, 20) -0.0004934872066542084\n",
      "(3, 21) 0.00013272694054933254\n",
      "(3, 22) -3.42911921080713e-05\n",
      "(3, 23) -0.009960299873768008\n",
      "(3, 24) 5.058313767847266e-05\n",
      "(3, 25) -2.5011392956741926e-05\n",
      "(3, 26) -8.1272633067897e-05\n",
      "(3, 27) 8.102580828506234e-05\n",
      "(3, 28) -0.0002759436679156124\n",
      "(3, 29) 1.0258904836746296e-05\n",
      "(4, 0) -0.0011574772695865931\n",
      "(4, 1) 0.0006367443683430452\n",
      "(4, 2) 0.00019151025210106806\n",
      "(4, 3) -9.819167701152764e-06\n",
      "(4, 4) -8.948886076609597e-06\n",
      "(4, 5) -3.352753630281313e-05\n",
      "(4, 6) 2.5826940586171073e-05\n",
      "(4, 7) 0.0011090087070897425\n",
      "(4, 8) 0.0002211145488928423\n",
      "(4, 9) -0.24874596102897326\n",
      "(4, 10) -1.2512968439182258e-05\n",
      "(4, 11) 2.3497870316191435e-05\n",
      "(4, 12) 2.273803367813798e-06\n",
      "(4, 13) 8.340106383286638e-06\n",
      "(4, 14) 0.022023554890893134\n",
      "(4, 15) -0.0002908109308918938\n",
      "(4, 16) 5.923506130045552e-06\n",
      "(4, 17) 0.00803812181260355\n",
      "(4, 18) -9.853673432758114e-06\n",
      "(4, 19) 2.4164603651399826e-05\n",
      "(4, 20) 0.0004936194786253623\n",
      "(4, 21) -0.00013276248989058104\n",
      "(4, 22) 3.4300384754715196e-05\n",
      "(4, 23) 0.009962969782506548\n",
      "(4, 24) -5.059672680829407e-05\n",
      "(4, 25) 2.501807649935017e-05\n",
      "(4, 26) 8.129443784810064e-05\n",
      "(4, 27) -8.104752424742401e-05\n",
      "(4, 28) 0.00027601765317797344\n",
      "(4, 29) -1.0261635985386874e-05\n",
      "(5, 0) -0.0011569110558440343\n",
      "(5, 1) 0.0006364329063757168\n",
      "(5, 2) 0.0001914165714822502\n",
      "(5, 3) -9.814371537686384e-06\n",
      "(5, 4) -8.944489593432081e-06\n",
      "(5, 5) -3.351112720650917e-05\n",
      "(5, 6) 2.5814284043690346e-05\n",
      "(5, 7) 0.0011084662299154502\n",
      "(5, 8) 0.0002210063909657833\n",
      "(5, 9) -0.2486242811183814\n",
      "(5, 10) -1.2506840008086327e-05\n",
      "(5, 11) 2.3486412814577303e-05\n",
      "(5, 12) 2.2726709403286804e-06\n",
      "(5, 13) 8.33604296701651e-06\n",
      "(5, 14) 0.022012781553115698\n",
      "(5, 15) -0.00029066868911797883\n",
      "(5, 16) 5.9206195501815265e-06\n",
      "(5, 17) 0.008034189757921695\n",
      "(5, 18) -9.848855064831241e-06\n",
      "(5, 19) 2.4152768673957322e-05\n",
      "(5, 20) 0.0004933780051175063\n",
      "(5, 21) -0.00013269754184364047\n",
      "(5, 22) 3.4283598182582864e-05\n",
      "(5, 23) 0.00995809616988197\n",
      "(5, 24) -5.057194663038444e-05\n",
      "(5, 25) 2.5005819637158307e-05\n",
      "(5, 26) 8.125466965935857e-05\n",
      "(5, 27) -8.100791148990538e-05\n",
      "(5, 28) 0.00027588260564925804\n",
      "(5, 29) -1.0256639981776061e-05\n",
      "(6, 0) 0.0011570446600828177\n",
      "(6, 1) -0.000636506403139947\n",
      "(6, 2) -0.00019143868712490073\n",
      "(6, 3) 9.815526169631994e-06\n",
      "(6, 4) 8.945510998614736e-06\n",
      "(6, 5) 3.351501298709536e-05\n",
      "(6, 6) -2.5817259441396342e-05\n",
      "(6, 7) -0.0011085941942212685\n",
      "(6, 8) -0.0002210319260953497\n",
      "(6, 9) 0.24865299139698036\n",
      "(6, 10) 1.2508305502478832e-05\n",
      "(6, 11) -2.3489077349836404e-05\n",
      "(6, 12) -2.2729373938545905e-06\n",
      "(6, 13) -8.336997758817688e-06\n",
      "(6, 14) -0.02201532349754842\n",
      "(6, 15) 0.0002907022622622435\n",
      "(6, 16) -5.9212856839963015e-06\n",
      "(6, 17) -0.008035117526894453\n",
      "(6, 18) 9.849965287855866e-06\n",
      "(6, 19) -2.4155544231518885e-05\n",
      "(6, 20) -0.0004934350039675905\n",
      "(6, 21) 0.00013271290733030128\n",
      "(6, 22) -3.428757278101102e-05\n",
      "(6, 23) -0.009959246094481955\n",
      "(6, 24) 5.057780860795446e-05\n",
      "(6, 25) -2.5008750625943318e-05\n",
      "(6, 26) -8.12640399416864e-05\n",
      "(6, 27) 8.101725956777273e-05\n",
      "(6, 28) -0.0002759144912545253\n",
      "(6, 29) 1.0257816818182164e-05\n",
      "(7, 0) 0.00115579545933997\n",
      "(7, 1) -0.0006358191972921645\n",
      "(7, 2) -0.00019123196359771552\n",
      "(7, 3) 9.80493464197707e-06\n",
      "(7, 4) 8.93587426276099e-06\n",
      "(7, 5) 3.3478775307571595e-05\n",
      "(7, 6) -2.578939284347825e-05\n",
      "(7, 7) -0.0011073973738007226\n",
      "(7, 8) -0.00022079327255397627\n",
      "(7, 9) 0.24838453818176728\n",
      "(7, 10) 1.249480519049939e-05\n",
      "(7, 11) -2.3463719855953965e-05\n",
      "(7, 12) -2.270494903200415e-06\n",
      "(7, 13) -8.327982747857732e-06\n",
      "(7, 14) -0.021991555132494508\n",
      "(7, 15) 0.00029038838000872147\n",
      "(7, 16) -5.914868594913968e-06\n",
      "(7, 17) -0.00802644257724694\n",
      "(7, 18) 9.83935155574045e-06\n",
      "(7, 19) -2.412949839936118e-05\n",
      "(7, 20) -0.0004929022745514544\n",
      "(7, 21) 0.00013256962194674315\n",
      "(7, 22) -3.425055794537002e-05\n",
      "(7, 23) -0.009948493762124144\n",
      "(7, 24) 5.05231856351429e-05\n",
      "(7, 25) -2.4981750001984434e-05\n",
      "(7, 26) -8.117628791382003e-05\n",
      "(7, 27) 8.092979619789276e-05\n",
      "(7, 28) -0.00027561659621255785\n",
      "(7, 29) 1.0246736792396405e-05\n",
      "(8, 0) -0.0011566680058194834\n",
      "(8, 1) 0.000636299191114631\n",
      "(8, 2) 0.00019137635920429827\n",
      "(8, 3) -9.812328727321074e-06\n",
      "(8, 4) -8.942602214290218e-06\n",
      "(8, 5) -3.350408839253305e-05\n",
      "(8, 6) 2.5808866155330176e-05\n",
      "(8, 7) 0.0011082333717382653\n",
      "(8, 8) 0.0002209599614388935\n",
      "(8, 9) -0.24857205132011725\n",
      "(8, 10) -1.2504219881748211e-05\n",
      "(8, 11) 2.3481439015426982e-05\n",
      "(8, 12) 2.2722268511188304e-06\n",
      "(8, 13) 8.33426661017711e-06\n",
      "(8, 14) 0.022008157207764608\n",
      "(8, 15) -0.00029060762685162445\n",
      "(8, 16) 5.919376100393946e-06\n",
      "(8, 17) 0.00803250199687966\n",
      "(8, 18) -9.846767845544946e-06\n",
      "(8, 19) 2.414770605696503e-05\n",
      "(8, 20) 0.0004932743769003878\n",
      "(8, 21) -0.00013266965304126188\n",
      "(8, 22) 3.427640393738329e-05\n",
      "(8, 23) 0.009956004221045589\n",
      "(8, 24) -5.056133289826902e-05\n",
      "(8, 25) 2.5000579384482077e-05\n",
      "(8, 26) 8.123759442923983e-05\n",
      "(8, 27) -8.099088066870763e-05\n",
      "(8, 28) 0.0002758246742118331\n",
      "(8, 29) -1.0254508353568781e-05\n",
      "(9, 0) 0.0011480623562931669\n",
      "(9, 1) -0.0006315651113197873\n",
      "(9, 2) -0.000189952520379677\n",
      "(9, 3) 9.739320461221723e-06\n",
      "(9, 4) 8.876077650654679e-06\n",
      "(9, 5) 3.325482111904421e-05\n",
      "(9, 6) -2.561684198099101e-05\n",
      "(9, 7) -0.0010999881006057421\n",
      "(9, 8) -0.00021931598759294954\n",
      "(9, 9) 0.24672266834002696\n",
      "(9, 10) 1.2411205396745116e-05\n",
      "(9, 11) -2.330675652473246e-05\n",
      "(9, 12) -2.2552848477630505e-06\n",
      "(9, 13) -8.272293960942534e-06\n",
      "(9, 14) -0.021844415920568846\n",
      "(9, 15) 0.00028844548971562745\n",
      "(9, 16) -5.8753446552373126e-06\n",
      "(9, 17) -0.007972740023731717\n",
      "(9, 18) 9.773515330380178e-06\n",
      "(9, 19) -2.3968027562659696e-05\n",
      "(9, 20) -0.0004896044014657264\n",
      "(9, 21) 0.00013168259815898864\n",
      "(9, 22) -3.4021385708626894e-05\n",
      "(9, 23) -0.009881931339883465\n",
      "(9, 24) 5.0185144928605034e-05\n",
      "(9, 25) -2.4814572618936378e-05\n",
      "(9, 26) -8.06331890146339e-05\n",
      "(9, 27) 8.038829601986208e-05\n",
      "(9, 28) -0.00027377251576865547\n",
      "(9, 29) 1.0178191622856048e-05\n",
      "(10, 0) 0.0011562791613073387\n",
      "(10, 1) -0.0006360852733422462\n",
      "(10, 2) -0.000191312010677791\n",
      "(10, 3) 9.80902026270769e-06\n",
      "(10, 4) 8.93960461212373e-06\n",
      "(10, 5) 3.349280852660286e-05\n",
      "(10, 6) -2.58002064157381e-05\n",
      "(10, 7) -0.001107860780891201\n",
      "(10, 8) -0.00022088568751854607\n",
      "(10, 9) 0.2484884859654812\n",
      "(10, 10) 1.2500001034254636e-05\n",
      "(10, 11) -2.347353422749165e-05\n",
      "(10, 12) -2.2714274905411003e-06\n",
      "(10, 13) -8.331491052615547e-06\n",
      "(10, 14) -0.02200075848168836\n",
      "(10, 15) 0.00029050992722545743\n",
      "(10, 16) -5.9173554944891285e-06\n",
      "(10, 17) -0.008029801623621324\n",
      "(10, 18) 9.843459380931563e-06\n",
      "(10, 19) -2.4139579224424775e-05\n",
      "(10, 20) -0.0004931085761938903\n",
      "(10, 21) 0.00013262506648459294\n",
      "(10, 22) -3.4264879822387684e-05\n",
      "(10, 23) -0.00995265718728433\n",
      "(10, 24) 5.0544324281531765e-05\n",
      "(10, 25) -2.499218609841591e-05\n",
      "(10, 26) -8.121028294283406e-05\n",
      "(10, 27) 8.096363579568333e-05\n",
      "(10, 28) -0.0002757319261803559\n",
      "(10, 29) 1.025104445773195e-05\n",
      "(11, 0) -0.0011561660961945108\n",
      "(11, 1) 0.0006360230786484067\n",
      "(11, 2) 0.0001912933145220563\n",
      "(11, 3) -9.808065470906513e-06\n",
      "(11, 4) -8.938738638164523e-06\n",
      "(11, 5) -3.348954447091046e-05\n",
      "(11, 6) 2.5797675107241954e-05\n",
      "(11, 7) 0.0011077524453284582\n",
      "(11, 8) 0.00022086406037402637\n",
      "(11, 9) -0.24846418207324913\n",
      "(11, 10) -1.249880199338804e-05\n",
      "(11, 11) 2.3471247168060924e-05\n",
      "(11, 12) 2.2712276503966677e-06\n",
      "(11, 13) 8.330669487577325e-06\n",
      "(11, 14) 0.021998606669626494\n",
      "(11, 15) -0.0002904815277204875\n",
      "(11, 16) 5.916822587437308e-06\n",
      "(11, 17) 0.008029016229649244\n",
      "(11, 18) -9.842504589130385e-06\n",
      "(11, 19) 2.413722555161257e-05\n",
      "(11, 20) 0.00049306032590124\n",
      "(11, 21) -0.0001326120990796653\n",
      "(11, 22) 3.426154915331381e-05\n",
      "(11, 23) 0.0099516837659408\n",
      "(11, 24) -5.053937268684194e-05\n",
      "(11, 25) 2.4989743607761735e-05\n",
      "(11, 26) 8.120235595043823e-05\n",
      "(11, 27) -8.0955731007748e-05\n",
      "(11, 28) 0.0002757049477608575\n",
      "(11, 29) -1.0250045257009788e-05\n",
      "(12, 0) -0.0011571980707003604\n",
      "(12, 1) 0.0006365908244987395\n",
      "(12, 2) 0.00019146406682324366\n",
      "(12, 3) -9.816791823880067e-06\n",
      "(12, 4) -8.946732243941824e-06\n",
      "(12, 5) -3.351945387919386e-05\n",
      "(12, 6) 2.582070113277268e-05\n",
      "(12, 7) 0.0011087412321586498\n",
      "(12, 8) 0.0002210612137787393\n",
      "(12, 9) -0.24868596490978942\n",
      "(12, 10) -1.2509948632555277e-05\n",
      "(12, 11) 2.3492185974305354e-05\n",
      "(12, 12) 2.2732482563014855e-06\n",
      "(12, 13) 8.33808577738182e-06\n",
      "(12, 14) 0.022018242940013973\n",
      "(12, 15) -0.0002907408092056585\n",
      "(12, 16) 5.922062840113539e-06\n",
      "(12, 17) 0.008036183074544567\n",
      "(12, 18) -9.851297555485417e-06\n",
      "(12, 19) 2.415878608275079e-05\n",
      "(12, 20) 0.000493500440512662\n",
      "(12, 21) -0.00013273049326301134\n",
      "(12, 22) 3.429210249095149e-05\n",
      "(12, 23) 0.009960566749178668\n",
      "(12, 24) -5.058446994610221e-05\n",
      "(12, 25) 2.5012036886096208e-05\n",
      "(12, 26) 8.127483130948576e-05\n",
      "(12, 27) -8.10279843221906e-05\n",
      "(12, 28) 0.00027595103979649593\n",
      "(12, 29) -1.0259171290272207e-05\n",
      "(13, 0) -0.0011571803737453479\n",
      "(13, 1) 0.0006365810545361228\n",
      "(13, 2) 0.00019146113583445865\n",
      "(13, 3) -9.816680801577604e-06\n",
      "(13, 4) -8.946576812718376e-06\n",
      "(13, 5) -3.351892097214204e-05\n",
      "(13, 6) 2.5820279248023322e-05\n",
      "(13, 7) 0.0011087242679508336\n",
      "(13, 8) 0.00022105783870074444\n",
      "(13, 9) -0.2486821591318744\n",
      "(13, 10) -1.2509748792410845e-05\n",
      "(13, 11) 2.3491830702937474e-05\n",
      "(13, 12) 2.2732038473805005e-06\n",
      "(13, 13) 8.33799695953985e-06\n",
      "(13, 14) 0.022017905987326\n",
      "(13, 15) -0.00029073636831356\n",
      "(13, 16) 5.921974022271569e-06\n",
      "(13, 17) 0.008036060061833439\n",
      "(13, 18) -9.851142124261969e-06\n",
      "(13, 19) 2.4158386402461925e-05\n",
      "(13, 20) 0.000493492868791634\n",
      "(13, 21) -0.00013272845045264603\n",
      "(13, 22) 3.4291591788360165e-05\n",
      "(13, 23) 0.009960414315557387\n",
      "(13, 24) -5.058375940336645e-05\n",
      "(13, 25) 2.5011681614728328e-05\n",
      "(13, 26) 8.127358785969818e-05\n",
      "(13, 27) -8.102674087240302e-05\n",
      "(13, 28) 0.00027594682094900236\n",
      "(13, 29) -1.0259015859048759e-05\n",
      "(14, 0) -0.001157205176127718\n",
      "(14, 1) 0.0006365946880748652\n",
      "(14, 2) 0.00019146524365964976\n",
      "(14, 3) -9.816858437261544e-06\n",
      "(14, 4) -8.946754448402316e-06\n",
      "(14, 5) -3.35196315148778e-05\n",
      "(14, 6) 2.5820812155075142e-05\n",
      "(14, 7) 0.0011087480045191\n",
      "(14, 8) 0.00022106259045528984\n",
      "(14, 9) -0.24868748607076438\n",
      "(14, 10) -1.2510015245936755e-05\n",
      "(14, 11) 2.3492363609989294e-05\n",
      "(14, 12) 2.273270460761978e-06\n",
      "(14, 13) 8.33817459522379e-06\n",
      "(14, 14) 0.02201837761006686\n",
      "(14, 15) -0.0002907425855624979\n",
      "(14, 16) 5.922107249034524e-06\n",
      "(14, 17) 0.008036232190811177\n",
      "(14, 18) -9.851341964406402e-06\n",
      "(14, 19) 2.4158897105053253e-05\n",
      "(14, 20) 0.0004935034381148284\n",
      "(14, 21) -0.00013273129262358907\n",
      "(14, 22) 3.429232453555642e-05\n",
      "(14, 23) 0.00996062770042272\n",
      "(14, 24) -5.058482521747009e-05\n",
      "(14, 25) 2.501221452178015e-05\n",
      "(14, 26) 8.12753198076166e-05\n",
      "(14, 27) -8.102847282032144e-05\n",
      "(14, 28) 0.00027595274953995386\n",
      "(14, 29) -1.0259215699193192e-05\n",
      "(15, 0) -0.0011561029911177911\n",
      "(15, 1) 0.0006359883508721964\n",
      "(15, 2) 0.00019128285622116434\n",
      "(15, 3) -9.807532563854693e-06\n",
      "(15, 4) -8.938227935573195e-06\n",
      "(15, 5) -3.3487723705150074e-05\n",
      "(15, 6) 2.579623181730994e-05\n",
      "(15, 7) 0.0011076920047869976\n",
      "(15, 8) 0.00022085204776089992\n",
      "(15, 9) -0.2484506270716835\n",
      "(15, 10) -1.249809145065228e-05\n",
      "(15, 11) 2.346998151381285e-05\n",
      "(15, 12) 2.2710944236337127e-06\n",
      "(15, 13) 8.330225398367475e-06\n",
      "(15, 14) 0.021997406518536874\n",
      "(15, 15) -0.0002904656515312354\n",
      "(15, 16) 5.916467316069428e-06\n",
      "(15, 17) 0.008028578224461569\n",
      "(15, 18) -9.841971682078565e-06\n",
      "(15, 19) 2.413589328398302e-05\n",
      "(15, 20) 0.0004930334362995836\n",
      "(15, 21) -0.00013260490483446574\n",
      "(15, 22) 3.4259661774171946e-05\n",
      "(15, 23) 0.009951140844677298\n",
      "(15, 24) -5.0536597129280374e-05\n",
      "(15, 25) 2.4988389135671692e-05\n",
      "(15, 26) 8.119793726280022e-05\n",
      "(15, 27) -8.09512901156495e-05\n",
      "(15, 28) 0.0002756899153411041\n",
      "(15, 29) -1.0249467941036983e-05\n",
      "(16, 0) -0.0011558835222302832\n",
      "(16, 1) 0.0006358676252204987\n",
      "(16, 2) 0.0001912465519282591\n",
      "(16, 3) -9.805667389173323e-06\n",
      "(16, 4) -8.936540396575765e-06\n",
      "(16, 5) -3.3481351024988726e-05\n",
      "(16, 6) 2.579134683600159e-05\n",
      "(16, 7) 0.0011074817285461336\n",
      "(16, 8) 0.00022081012573949008\n",
      "(16, 9) -0.2484034633987164\n",
      "(16, 10) -1.2495715573379583e-05\n",
      "(16, 11) 2.3465518417253858e-05\n",
      "(16, 12) 2.2706503344238627e-06\n",
      "(16, 13) 8.328648881672507e-06\n",
      "(16, 14) 0.021993230725492193\n",
      "(16, 15) -0.000290410495651372\n",
      "(16, 16) 5.915357093044803e-06\n",
      "(16, 17) 0.008027054132497824\n",
      "(16, 18) -9.840084302936702e-06\n",
      "(16, 19) 2.4131341369582057e-05\n",
      "(16, 20) 0.0004929398444986077\n",
      "(16, 21) -0.00013257970277180675\n",
      "(16, 22) 3.425313366278715e-05\n",
      "(16, 23) 0.009949251822405358\n",
      "(16, 24) -5.052700480234761e-05\n",
      "(16, 25) 2.4983615176665804e-05\n",
      "(16, 26) 8.118248295829744e-05\n",
      "(16, 27) -8.093594683344918e-05\n",
      "(16, 28) 0.00027563757942772327\n",
      "(16, 29) -1.024749174405315e-05\n",
      "(17, 0) -0.0005327003727018109\n",
      "(17, 1) 0.0002930458986583062\n",
      "(17, 2) 8.81378525718901e-05\n",
      "(17, 3) -4.519029594973745e-06\n",
      "(17, 4) -4.118505536609973e-06\n",
      "(17, 5) -1.5430234867608306e-05\n",
      "(17, 6) 1.1886225337320864e-05\n",
      "(17, 7) 0.0005103939271222657\n",
      "(17, 8) 0.00010176250953009001\n",
      "(17, 9) -0.11447913699225153\n",
      "(17, 10) -5.758771237651671e-06\n",
      "(17, 11) 1.0814282802584783e-05\n",
      "(17, 12) 1.0464518140906875e-06\n",
      "(17, 13) 3.838329654115569e-06\n",
      "(17, 14) 0.0101357934489954\n",
      "(17, 15) -0.00013383856245496872\n",
      "(17, 16) 2.726174841427564e-06\n",
      "(17, 17) 0.0036993471619339853\n",
      "(17, 18) -4.534905784225884e-06\n",
      "(17, 19) 1.1121148446591176e-05\n",
      "(17, 20) 0.0002271762111760722\n",
      "(17, 21) -6.110068007103564e-05\n",
      "(17, 22) 1.578590591577722e-05\n",
      "(17, 23) 0.004585210211516255\n",
      "(17, 24) -2.3285862127409015e-05\n",
      "(17, 25) 1.1513945352703557e-05\n",
      "(17, 26) 3.741376097821103e-05\n",
      "(17, 27) -3.73001185494104e-05\n",
      "(17, 28) 0.0001270302973921389\n",
      "(17, 29) -4.722666702150491e-06\n",
      "(18, 0) 0.0011562884427718245\n",
      "(18, 1) -0.00063609040257262\n",
      "(18, 2) -0.00019131356499002547\n",
      "(18, 3) 9.80910908054966e-06\n",
      "(18, 4) 8.939649021044715e-06\n",
      "(18, 5) 3.349309718458926e-05\n",
      "(18, 6) -2.580038405142204e-05\n",
      "(18, 7) -0.001107869707084319\n",
      "(18, 8) -0.00022088746387538547\n",
      "(18, 9) 0.24849048299024898\n",
      "(18, 10) 1.250013426101759e-05\n",
      "(18, 11) -2.347371186317559e-05\n",
      "(18, 12) -2.2714496950015928e-06\n",
      "(18, 13) -8.331535461536532e-06\n",
      "(18, 14) -0.022000935295807263\n",
      "(18, 15) 0.00029051223648934865\n",
      "(18, 16) -5.9174443123310985e-06\n",
      "(18, 17) -0.008029866149783516\n",
      "(18, 18) 9.843548198773533e-06\n",
      "(18, 19) -2.4139779064569208e-05\n",
      "(18, 20) -0.0004931124841789369\n",
      "(18, 21) 0.00013262613229869658\n",
      "(18, 22) -3.4265146275913594e-05\n",
      "(18, 23) -0.009952737189955485\n",
      "(18, 24) 5.054474616628112e-05\n",
      "(18, 25) -2.4992408143020836e-05\n",
      "(18, 26) -8.121092687218834e-05\n",
      "(18, 27) 8.096427972503761e-05\n",
      "(18, 28) -0.00027573414662640516\n",
      "(18, 29) 1.025113327557392e-05\n",
      "(19, 0) 0.0011562018453759038\n",
      "(19, 1) -0.0006360427295959425\n",
      "(19, 2) -0.0001912992209085473\n",
      "(19, 3) 9.808354128892915e-06\n",
      "(19, 4) 8.939027296150925e-06\n",
      "(19, 5) 3.349058808055361e-05\n",
      "(19, 6) -2.579845226335919e-05\n",
      "(19, 7) -0.001107786751219919\n",
      "(19, 8) -0.00022087089934785806\n",
      "(19, 9) 0.2484718714779177\n",
      "(19, 10) 1.249915726475592e-05\n",
      "(19, 11) -2.3471979915257176e-05\n",
      "(19, 12) -2.2712942637781453e-06\n",
      "(19, 13) -8.330935941103235e-06\n",
      "(19, 14) -0.021999287458385194\n",
      "(19, 15) 0.0002904904983225265\n",
      "(19, 16) -5.9170002231212484e-06\n",
      "(19, 17) -0.008029264719766616\n",
      "(19, 18) 9.84281545157728e-06\n",
      "(19, 19) -2.4137958298808823e-05\n",
      "(19, 20) -0.0004930755803655984\n",
      "(19, 21) 0.00013261620690485643\n",
      "(19, 22) -3.426261496741745e-05\n",
      "(19, 23) -0.00995199171960337\n",
      "(19, 24) 5.0540949203536904e-05\n",
      "(19, 25) -2.4990520763878973e-05\n",
      "(19, 26) -8.120486505447388e-05\n",
      "(19, 27) 8.095824011178365e-05\n",
      "(19, 28) -0.00027571347427368664\n",
      "(19, 29) 1.025033391499619e-05\n",
      "W2 relative error: 1.00e+00\n",
      "(0, 0) 0.0\n",
      "(0, 1) 0.0\n",
      "(0, 2) 0.0\n",
      "(0, 3) 0.0\n",
      "(0, 4) 0.05373403866304471\n",
      "(0, 5) 0.05718522886333232\n",
      "(0, 6) 0.0\n",
      "(0, 7) 0.04897695933259171\n",
      "(0, 8) 0.0\n",
      "(0, 9) 0.0\n",
      "(1, 0) 0.0\n",
      "(1, 1) 0.0\n",
      "(1, 2) 0.0\n",
      "(1, 3) 0.0\n",
      "(1, 4) 0.05374086478049377\n",
      "(1, 5) 0.05719249336344489\n",
      "(1, 6) 0.0\n",
      "(1, 7) 0.04898318108903509\n",
      "(1, 8) 0.0\n",
      "(1, 9) 0.0\n",
      "(2, 0) 0.0\n",
      "(2, 1) 0.0\n",
      "(2, 2) 0.0\n",
      "(2, 3) 0.0\n",
      "(2, 4) 0.05386844412758051\n",
      "(2, 5) 0.057328266822587175\n",
      "(2, 6) 0.0\n",
      "(2, 7) 0.04909946582642987\n",
      "(2, 8) 0.0\n",
      "(2, 9) 0.0\n",
      "(3, 0) 0.0\n",
      "(3, 1) 0.0\n",
      "(3, 2) 0.0\n",
      "(3, 3) 0.0\n",
      "(3, 4) 0.05399551783469291\n",
      "(3, 5) 0.057463502134424964\n",
      "(3, 6) 0.0\n",
      "(3, 7) 0.04921528973245159\n",
      "(3, 8) 0.0\n",
      "(3, 9) 0.0\n",
      "(4, 0) 0.0\n",
      "(4, 1) 0.0\n",
      "(4, 2) 0.0\n",
      "(4, 3) 0.0\n",
      "(4, 4) 0.054002063820668404\n",
      "(4, 5) 0.05747046851745096\n",
      "(4, 6) 0.0\n",
      "(4, 7) 0.049221256159803765\n",
      "(4, 8) 0.0\n",
      "(4, 9) 0.0\n",
      "(5, 0) 0.059476259517410306\n",
      "(5, 1) 0.0\n",
      "(5, 2) 0.0\n",
      "(5, 3) 0.0\n",
      "(5, 4) 0.0\n",
      "(5, 5) 0.04911472202273614\n",
      "(5, 6) 0.04696487472255483\n",
      "(5, 7) -0.4465981666479379\n",
      "(5, 8) 0.0\n",
      "(5, 9) 0.05888977476775636\n",
      "(6, 0) 0.0\n",
      "(6, 1) 0.0\n",
      "(6, 2) 0.0\n",
      "(6, 3) 0.0\n",
      "(6, 4) 0.05399998825872387\n",
      "(6, 5) 0.05746825966213009\n",
      "(6, 6) 0.0\n",
      "(6, 7) 0.049219364384178725\n",
      "(6, 8) 0.0\n",
      "(6, 9) 0.0\n",
      "(7, 0) 0.05925842301301997\n",
      "(7, 1) 0.0\n",
      "(7, 2) 0.0\n",
      "(7, 3) 0.0\n",
      "(7, 4) 0.0\n",
      "(7, 5) 0.04893483549484045\n",
      "(7, 6) 0.04679286216280331\n",
      "(7, 7) -0.4449624657176798\n",
      "(7, 8) 0.0\n",
      "(7, 9) 0.05867408634507853\n",
      "(8, 0) 0.059405382391020105\n",
      "(8, 1) 0.0\n",
      "(8, 2) 0.0\n",
      "(8, 3) 0.0\n",
      "(8, 4) 0.0\n",
      "(8, 5) 0.049056192596985675\n",
      "(8, 6) 0.04690890724745599\n",
      "(8, 7) -0.4460659611460471\n",
      "(8, 8) 0.0\n",
      "(8, 9) 0.05881959657116908\n",
      "(9, 0) 0.05416709834005217\n",
      "(9, 1) 0.0\n",
      "(9, 2) 0.0\n",
      "(9, 3) 0.0\n",
      "(9, 4) 0.0\n",
      "(9, 5) 0.04473048573760962\n",
      "(9, 6) 0.04277254501694471\n",
      "(9, 7) -0.4067324846257491\n",
      "(9, 8) 0.0\n",
      "(9, 9) 0.053632966290351185\n",
      "(10, 0) 0.059482475744943024\n",
      "(10, 1) 0.0\n",
      "(10, 2) 0.0\n",
      "(10, 3) 0.0\n",
      "(10, 4) 0.0\n",
      "(10, 5) 0.04911985529432172\n",
      "(10, 6) 0.046969783307204686\n",
      "(10, 7) -0.44664484339929084\n",
      "(10, 8) 0.0\n",
      "(10, 9) 0.058895929710978116\n",
      "(11, 0) 0.059473229807593946\n",
      "(11, 1) 0.0\n",
      "(11, 2) 0.0\n",
      "(11, 3) 0.0\n",
      "(11, 4) 0.0\n",
      "(11, 5) 0.049112220112945686\n",
      "(11, 6) 0.04696248232516353\n",
      "(11, 7) -0.4465754171345537\n",
      "(11, 8) 0.0\n",
      "(11, 9) 0.05888677496734828\n",
      "(12, 0) 0.05947652355065002\n",
      "(12, 1) 0.0\n",
      "(12, 2) 0.0\n",
      "(12, 3) 0.0\n",
      "(12, 4) 0.0\n",
      "(12, 5) 0.049114940070538175\n",
      "(12, 6) 0.046965083200234396\n",
      "(12, 7) -0.4466001493730331\n",
      "(12, 8) 0.0\n",
      "(12, 9) 0.05889003622527866\n",
      "(13, 0) 0.059482391479015455\n",
      "(13, 1) 0.0\n",
      "(13, 2) 0.0\n",
      "(13, 3) 0.0\n",
      "(13, 4) 0.0\n",
      "(13, 5) 0.049119785727746994\n",
      "(13, 6) 0.04696971678264105\n",
      "(13, 7) -0.44664421081641587\n",
      "(13, 8) 0.0\n",
      "(13, 9) 0.058895846288820046\n",
      "(14, 0) 0.0\n",
      "(14, 1) 0.0\n",
      "(14, 2) 0.0\n",
      "(14, 3) 0.0\n",
      "(14, 4) 0.04982455925617301\n",
      "(14, 5) 0.05302465428957958\n",
      "(14, 6) 0.0\n",
      "(14, 7) 0.045413586469145166\n",
      "(14, 8) 0.0\n",
      "(14, 9) 0.0\n",
      "(15, 0) 0.059402332341917934\n",
      "(15, 1) 0.0\n",
      "(15, 2) 0.0\n",
      "(15, 3) 0.0\n",
      "(15, 4) 0.0\n",
      "(15, 5) 0.04905367392282755\n",
      "(15, 6) 0.04690649879623975\n",
      "(15, 7) -0.4460430588437702\n",
      "(15, 8) 0.0\n",
      "(15, 9) 0.058816576609110875\n",
      "(16, 0) 0.0\n",
      "(16, 1) 0.0\n",
      "(16, 2) 0.0\n",
      "(16, 3) 0.0\n",
      "(16, 4) 0.05398719833404896\n",
      "(16, 5) 0.05745464828343926\n",
      "(16, 6) 0.0\n",
      "(16, 7) 0.049207706709353254\n",
      "(16, 8) 0.0\n",
      "(16, 9) 0.0\n",
      "(17, 0) 0.05890177461331802\n",
      "(17, 1) 0.0\n",
      "(17, 2) 0.0\n",
      "(17, 3) 0.0\n",
      "(17, 4) 0.0\n",
      "(17, 5) 0.04864031983853322\n",
      "(17, 6) 0.046511238060986664\n",
      "(17, 7) -0.4422844470441944\n",
      "(17, 8) 0.0\n",
      "(17, 9) 0.05832095475444276\n",
      "(18, 0) 0.059395856877308965\n",
      "(18, 1) 0.0\n",
      "(18, 2) 0.0\n",
      "(18, 3) 0.0\n",
      "(18, 4) 0.0\n",
      "(18, 5) 0.0490483265558339\n",
      "(18, 6) 0.04690138548646416\n",
      "(18, 7) -0.4459944354717748\n",
      "(18, 8) 0.0\n",
      "(18, 9) 0.05881016498232582\n",
      "(19, 0) 0.059474734737108285\n",
      "(19, 1) 0.0\n",
      "(19, 2) 0.0\n",
      "(19, 3) 0.0\n",
      "(19, 4) 0.0\n",
      "(19, 5) 0.04911346289659945\n",
      "(19, 6) 0.04696367070788909\n",
      "(19, 7) -0.44658671751740536\n",
      "(19, 8) 0.0\n",
      "(19, 9) 0.05888826506428301\n",
      "(20, 0) 0.05944843792793363\n",
      "(20, 1) 0.0\n",
      "(20, 2) 0.0\n",
      "(20, 3) 0.0\n",
      "(20, 4) 0.0\n",
      "(20, 5) 0.04909174731171361\n",
      "(20, 6) 0.04694290565154801\n",
      "(20, 7) -0.44638925853490713\n",
      "(20, 8) 0.0\n",
      "(20, 9) 0.05886222753659353\n",
      "(21, 0) 0.05946748125040812\n",
      "(21, 1) 0.0\n",
      "(21, 2) 0.0\n",
      "(21, 3) 0.0\n",
      "(21, 4) 0.0\n",
      "(21, 5) 0.04910747302133699\n",
      "(21, 6) 0.046957943045100585\n",
      "(21, 7) -0.44653225199642316\n",
      "(21, 8) 0.0\n",
      "(21, 9) 0.05888108307594563\n",
      "(22, 0) 0.0\n",
      "(22, 1) 0.0\n",
      "(22, 2) 0.0\n",
      "(22, 3) 0.0\n",
      "(22, 4) 0.053963573454218754\n",
      "(22, 5) 0.05742950603959684\n",
      "(22, 6) 0.0\n",
      "(22, 7) 0.049186173378679136\n",
      "(22, 8) 0.0\n",
      "(22, 9) 0.0\n",
      "(23, 0) 0.0\n",
      "(23, 1) 0.0\n",
      "(23, 2) 0.0\n",
      "(23, 3) 0.0\n",
      "(23, 4) 0.05229605102297085\n",
      "(23, 5) 0.05565488321312983\n",
      "(23, 6) 0.0\n",
      "(23, 7) 0.04766627683672197\n",
      "(23, 8) 0.0\n",
      "(23, 9) 0.0\n",
      "(24, 0) 0.0\n",
      "(24, 1) 0.0\n",
      "(24, 2) 0.0\n",
      "(24, 3) 0.0\n",
      "(24, 4) 0.05396161175674762\n",
      "(24, 5) 0.05742741830960795\n",
      "(24, 6) 0.0\n",
      "(24, 7) 0.04918438532008906\n",
      "(24, 8) 0.0\n",
      "(24, 9) 0.0\n",
      "(25, 0) 0.0\n",
      "(25, 1) 0.0\n",
      "(25, 2) 0.0\n",
      "(25, 3) 0.0\n",
      "(25, 4) 0.054004924443518114\n",
      "(25, 5) 0.057473512860006785\n",
      "(25, 6) 0.0\n",
      "(25, 7) 0.0492238635185771\n",
      "(25, 8) 0.0\n",
      "(25, 9) 0.0\n",
      "(26, 0) 0.05946429613157277\n",
      "(26, 1) 0.0\n",
      "(26, 2) 0.0\n",
      "(26, 3) 0.0\n",
      "(26, 4) 0.0\n",
      "(26, 5) 0.049104842814173814\n",
      "(26, 6) 0.04695542792365614\n",
      "(26, 7) -0.44650833541659546\n",
      "(26, 8) 0.0\n",
      "(26, 9) 0.05887792937642188\n",
      "(27, 0) 0.05946166292680743\n",
      "(27, 1) 0.0\n",
      "(27, 2) 0.0\n",
      "(27, 3) 0.0\n",
      "(27, 4) 0.0\n",
      "(27, 5) 0.049102668353562244\n",
      "(27, 6) 0.0469533486535667\n",
      "(27, 7) -0.4464885631882964\n",
      "(27, 8) 0.0\n",
      "(27, 9) 0.05887532215087531\n",
      "(28, 0) 0.059354446424464406\n",
      "(28, 1) 0.0\n",
      "(28, 2) 0.0\n",
      "(28, 3) 0.0\n",
      "(28, 4) 0.0\n",
      "(28, 5) 0.04901413039881674\n",
      "(28, 6) 0.046868686176537715\n",
      "(28, 7) -0.4456834909349893\n",
      "(28, 8) 0.0\n",
      "(28, 9) 0.05876916286950972\n",
      "(29, 0) 0.0\n",
      "(29, 1) 0.0\n",
      "(29, 2) 0.0\n",
      "(29, 3) 0.0\n",
      "(29, 4) 0.05399628522084753\n",
      "(29, 5) 0.05746431877007296\n",
      "(29, 6) 0.0\n",
      "(29, 7) 0.04921598912854818\n",
      "(29, 8) 0.0\n",
      "(29, 9) 0.0\n",
      "W3 relative error: 3.01e-10\n",
      "(0,) 0.0\n",
      "(1,) 0.0\n",
      "(2,) 0.0\n",
      "(3,) 0.0\n",
      "(4,) 0.0\n",
      "(5,) 0.0\n",
      "(6,) 0.0\n",
      "(7,) 0.0\n",
      "(8,) 0.0\n",
      "(9,) 0.0\n",
      "(10,) 0.0\n",
      "(11,) 0.0\n",
      "(12,) 0.0\n",
      "(13,) 0.0\n",
      "(14,) 0.0\n",
      "(15,) 0.0\n",
      "(16,) 0.0\n",
      "(17,) 0.0\n",
      "(18,) 0.0\n",
      "(19,) 0.0\n",
      "b1 relative error: 3.74e-23\n",
      "(0,) 0.0\n",
      "(1,) 0.0\n",
      "(2,) 0.0\n",
      "(3,) 0.0\n",
      "(4,) 0.0\n",
      "(5,) 0.0\n",
      "(6,) 0.0\n",
      "(7,) 0.0\n",
      "(8,) 0.0\n",
      "(9,) 0.0\n",
      "(10,) 0.0\n",
      "(11,) 0.0\n",
      "(12,) 0.0\n",
      "(13,) 0.0\n",
      "(14,) 0.0\n",
      "(15,) 0.0\n",
      "(16,) 0.0\n",
      "(17,) 0.0\n",
      "(18,) 0.0\n",
      "(19,) 0.0\n",
      "(20,) 0.0\n",
      "(21,) 0.0\n",
      "(22,) 0.0\n",
      "(23,) 0.0\n",
      "(24,) 0.0\n",
      "(25,) 0.0\n",
      "(26,) 0.0\n",
      "(27,) 0.0\n",
      "(28,) 0.0\n",
      "(29,) 0.0\n",
      "b2 relative error: 2.72e-07\n",
      "(0,) 0.05948911236952625\n",
      "(1,) 0.0\n",
      "(2,) 0.0\n",
      "(3,) 0.0\n",
      "(4,) 0.054021442186247264\n",
      "(5,) 0.1066164272423009\n",
      "(6,) 0.046975023870743364\n",
      "(7,) -0.3974557579056181\n",
      "(8,) 0.0\n",
      "(9,) 0.05890250089901627\n",
      "b3 relative error: 1.69e-10\n",
      "(0,) -0.014686582372469557\n",
      "(1,) 0.004955313870347311\n",
      "(2,) 0.0019899557113234323\n",
      "(3,) -0.0243607047423211\n",
      "(4,) 0.013385307418012358\n",
      "(5,) 0.010825988328022616\n",
      "(6,) 0.02392585480848197\n",
      "(7,) -0.016564454385914473\n",
      "(8,) -0.0017084527792476931\n",
      "(9,) -0.0037609325431731118\n",
      "(10,) -0.005256845159173906\n",
      "(11,) -0.00796169252748058\n",
      "(12,) -0.010130496774785058\n",
      "(13,) 0.009449229243507773\n",
      "(14,) -0.006168030974862403\n",
      "(15,) -0.002613072291879348\n",
      "(16,) 0.009624187535806072\n",
      "(17,) -0.00378491853414431\n",
      "(18,) 0.018596190587416572\n",
      "(19,) -0.000721300219552745\n",
      "beta1 relative error: 1.00e+00\n",
      "(0,) -0.006696909893300073\n",
      "(1,) 0.0038189576612168703\n",
      "(2,) 0.002847417723828016\n",
      "(3,) -0.0020894655117231764\n",
      "(4,) -0.0029462817519032565\n",
      "(5,) 0.023612601518507855\n",
      "(6,) 0.007299740434341117\n",
      "(7,) -0.010299824726445195\n",
      "(8,) -0.009374028442366011\n",
      "(9,) 0.022265121257802886\n",
      "(10,) 0.023749079747226173\n",
      "(11,) -0.01204776483021419\n",
      "(12,) -0.0016520141477016634\n",
      "(13,) -0.015532509500815193\n",
      "(14,) 0.002413633715114827\n",
      "(15,) 0.011684987333282491\n",
      "(16,) 0.0008303795873132457\n",
      "(17,) -0.018459431938566695\n",
      "(18,) 0.00035544178711433\n",
      "(19,) -0.014384658575394836\n",
      "(20,) -0.06177378197858018\n",
      "(21,) 0.04282989383153079\n",
      "(22,) 0.0021895112833902886\n",
      "(23,) 0.003998613196110057\n",
      "(24,) -0.0030723076971383985\n",
      "(25,) 0.010466276734177882\n",
      "(26,) -0.021343438638687925\n",
      "(27,) 0.01829202376235628\n",
      "(28,) -0.005740633945983119\n",
      "(29,) -0.002284264732921315\n",
      "beta2 relative error: 5.92e-09\n",
      "(0,) -0.008228873316085128\n",
      "(1,) 0.004924823726604188\n",
      "(2,) 0.001968499963034276\n",
      "(3,) -0.024352458471987855\n",
      "(4,) 0.013384363173329914\n",
      "(5,) 0.010819929219252343\n",
      "(6,) 0.023915225288995142\n",
      "(7,) -0.01653921981592532\n",
      "(8,) -0.001707137875506248\n",
      "(9,) -0.003730078068642228\n",
      "(10,) -0.0052510334080935195\n",
      "(11,) -0.007952112568432312\n",
      "(12,) -0.010127338878618275\n",
      "(13,) 0.009446139159763334\n",
      "(14,) -0.006166145971597813\n",
      "(15,) -0.0026097857208640107\n",
      "(16,) 0.009610258056014231\n",
      "(17,) -0.0017417925768370421\n",
      "(18,) 0.018575780647012152\n",
      "(19,) -0.0007204545848793486\n",
      "gamma1 relative error: 1.00e+00\n",
      "(0,) -0.006661281215514236\n",
      "(1,) 0.0037991227053169037\n",
      "(2,) 0.0028393533302306646\n",
      "(3,) -0.0020884628249007164\n",
      "(4,) -0.0029452248639927343\n",
      "(5,) 0.0236074999326874\n",
      "(6,) 0.007296841486592597\n",
      "(7,) -0.010259883653773727\n",
      "(8,) -0.009360834640759208\n",
      "(9,) 0.020273239309531732\n",
      "(10,) 0.023746430266591286\n",
      "(11,) -0.012044548292067246\n",
      "(12,) -0.001651664538471209\n",
      "(13,) -0.015530754704506931\n",
      "(14,) 0.0022261204213336327\n",
      "(15,) 0.011667941812731895\n",
      "(16,) 0.0008298532305772709\n",
      "(17,) -0.01827718141278467\n",
      "(18,) 0.00035488456617827063\n",
      "(19,) -0.014381182067424446\n",
      "(20,) -0.06173154543098746\n",
      "(21,) 0.04281432024466624\n",
      "(22,) 0.0021871658262284654\n",
      "(23,) 0.0038709014882343236\n",
      "(24,) -0.0030689049967946853\n",
      "(25,) 0.01046307656071832\n",
      "(26,) -0.02133453507191518\n",
      "(27,) 0.01828358346944725\n",
      "(28,) -0.005727638829888803\n",
      "(29,) -0.00228320096162804\n",
      "gamma2 relative error: 3.79e-08\n",
      "\n",
      "Running check with reg =  3.14\n",
      "Initial loss:  7.003236268442882\n",
      "(0, 0) -0.045515173940913194\n",
      "(0, 1) -0.26321883836999405\n",
      "(0, 2) 0.23514848255246076\n",
      "(0, 3) 0.026261079977274445\n",
      "(0, 4) -0.028351319691921614\n",
      "(0, 5) -0.16144126675499137\n",
      "(0, 6) -0.004918939033871084\n",
      "(0, 7) -0.05536158602659213\n",
      "(0, 8) -0.14174031814917498\n",
      "(0, 9) 0.014367813339077882\n",
      "(0, 10) -0.21037602753182225\n",
      "(0, 11) 0.2029243248991008\n",
      "(0, 12) -0.04707664089664831\n",
      "(0, 13) -0.3409753548400118\n",
      "(0, 14) 0.08296636502258536\n",
      "(0, 15) 0.19131516655335187\n",
      "(0, 16) 0.21989488239171348\n",
      "(0, 17) 0.29061023618659476\n",
      "(0, 18) 0.0495519773213715\n",
      "(0, 19) 0.044278842503686626\n",
      "(1, 0) 0.14471716958119885\n",
      "(1, 1) -0.07426264212462286\n",
      "(1, 2) 0.1867059932880721\n",
      "(1, 3) -0.14663555130134398\n",
      "(1, 4) -0.15784958131703775\n",
      "(1, 5) -0.21332434365639583\n",
      "(1, 6) 0.21706486905692654\n",
      "(1, 7) 0.21441970297075838\n",
      "(1, 8) 0.0786230901272944\n",
      "(1, 9) -0.5409314549620348\n",
      "(1, 10) 0.023653659386724254\n",
      "(1, 11) -0.20323918112907788\n",
      "(1, 12) 0.02441515376538916\n",
      "(1, 13) -0.262363397673937\n",
      "(1, 14) 0.28099806486103773\n",
      "(1, 15) 0.012678728911197366\n",
      "(1, 16) 0.02978881901150032\n",
      "(1, 17) 0.41444671188273213\n",
      "(1, 18) 0.24908363802644826\n",
      "(1, 19) -0.16653475514161187\n",
      "(2, 0) 0.06076977845381747\n",
      "(2, 1) 0.06391455893428599\n",
      "(2, 2) -0.12119623535866707\n",
      "(2, 3) -0.4611844321544822\n",
      "(2, 4) 0.03501636989255985\n",
      "(2, 5) -0.01003438074853591\n",
      "(2, 6) 0.17812646522230577\n",
      "(2, 7) 0.02825671603368107\n",
      "(2, 8) -0.09920557348941371\n",
      "(2, 9) 0.11038118383766003\n",
      "(2, 10) 0.3076921587297221\n",
      "(2, 11) 0.07601501126330845\n",
      "(2, 12) -0.38284838308477726\n",
      "(2, 13) -0.23077608899413346\n",
      "(2, 14) -0.191597477749994\n",
      "(2, 15) 0.07117342084583811\n",
      "(2, 16) 0.15651472526911903\n",
      "(2, 17) 0.03260454710662941\n",
      "(2, 18) 0.4164113166282845\n",
      "(2, 19) 0.33671819421599025\n",
      "(3, 0) -0.05199727497462447\n",
      "(3, 1) 0.17658429793954153\n",
      "(3, 2) -0.028112284145009877\n",
      "(3, 3) 0.18599918152339964\n",
      "(3, 4) -0.014941768178289292\n",
      "(3, 5) 0.06899245912350693\n",
      "(3, 6) 0.12223963850033213\n",
      "(3, 7) -0.26075900430022614\n",
      "(3, 8) -0.12945063359026676\n",
      "(3, 9) -0.2277057994160003\n",
      "(3, 10) -0.021364086766340048\n",
      "(3, 11) 0.04739746755078044\n",
      "(3, 12) -0.17521842026191334\n",
      "(3, 13) -0.060039837990188964\n",
      "(3, 14) 0.0293772651094315\n",
      "(3, 15) -0.057441529621726765\n",
      "(3, 16) 0.24007874057652143\n",
      "(3, 17) -0.14416057902977286\n",
      "(3, 18) -0.07111505646584249\n",
      "(3, 19) -0.2789614530485096\n",
      "(4, 0) 0.21050433440805702\n",
      "(4, 1) 0.08717241661848617\n",
      "(4, 2) 0.04920848297729207\n",
      "(4, 3) -0.10491150024272143\n",
      "(4, 4) -0.23356565930221504\n",
      "(4, 5) -0.13931930675781246\n",
      "(4, 6) 0.06624902950669309\n",
      "(4, 7) 0.07218188216029375\n",
      "(4, 8) -0.09829841212116718\n",
      "(4, 9) 0.3085349183251651\n",
      "(4, 10) 0.0022168519464571546\n",
      "(4, 11) 0.23802433668507203\n",
      "(4, 12) 0.023598989384865373\n",
      "(4, 13) 0.09619287171247491\n",
      "(4, 14) -0.003632083078741743\n",
      "(4, 15) -0.07187226329641305\n",
      "(4, 16) -0.2224773540504543\n",
      "(4, 17) 0.22114815863005785\n",
      "(4, 18) -0.05303572723214244\n",
      "(4, 19) -0.15192772999661486\n",
      "(5, 0) 0.13230804700725685\n",
      "(5, 1) 0.2875175380889772\n",
      "(5, 2) 0.00016767338628653758\n",
      "(5, 3) -0.07978045806211753\n",
      "(5, 4) 0.04160909163886117\n",
      "(5, 5) -0.058193091545533086\n",
      "(5, 6) -0.030678103701831102\n",
      "(5, 7) 0.07196392228792092\n",
      "(5, 8) 0.16762936088099423\n",
      "(5, 9) 0.06873935491924499\n",
      "(5, 10) -0.12155110287181968\n",
      "(5, 11) 0.21198436366276494\n",
      "(5, 12) 0.08591318891859599\n",
      "(5, 13) -0.04206337846923702\n",
      "(5, 14) 0.043217354317448546\n",
      "(5, 15) 0.017708817701134194\n",
      "(5, 16) -0.042368259034475386\n",
      "(5, 17) -0.04035760405862732\n",
      "(5, 18) -0.011508687869365984\n",
      "(5, 19) -0.1489266429732794\n",
      "(6, 0) -0.02089058153131873\n",
      "(6, 1) 0.40418720819168635\n",
      "(6, 2) 0.07874906167160134\n",
      "(6, 3) -0.13840496428940696\n",
      "(6, 4) -0.14427386831883382\n",
      "(6, 5) 0.07090527707198646\n",
      "(6, 6) 0.027103509259163158\n",
      "(6, 7) -0.3703746322081258\n",
      "(6, 8) 0.08491212253325385\n",
      "(6, 9) 0.006129313590008677\n",
      "(6, 10) 0.09835522760681668\n",
      "(6, 11) -0.27387592576033626\n",
      "(6, 12) -0.0928345682993381\n",
      "(6, 13) -0.02271283858767958\n",
      "(6, 14) -0.17741853679531513\n",
      "(6, 15) 0.15218947782003056\n",
      "(6, 16) -0.17654437085568017\n",
      "(6, 17) -0.2634875587936847\n",
      "(6, 18) -0.20301484213725016\n",
      "(6, 19) -0.3010674494596799\n",
      "(7, 0) -0.027310093075882943\n",
      "(7, 1) -0.0659243698297729\n",
      "(7, 2) 0.10751269914344162\n",
      "(7, 3) -0.14028977295410527\n",
      "(7, 4) -0.26910341395236514\n",
      "(7, 5) -0.01831087463877168\n",
      "(7, 6) -0.19428742903393467\n",
      "(7, 7) -0.01857426754625635\n",
      "(7, 8) -0.28420993638533787\n",
      "(7, 9) 0.02160095480263635\n",
      "(7, 10) 0.04865531910702713\n",
      "(7, 11) 0.08149532266799042\n",
      "(7, 12) 0.06707547322015728\n",
      "(7, 13) 0.14844451219353516\n",
      "(7, 14) -0.2367264852587425\n",
      "(7, 15) -0.08525236858680783\n",
      "(7, 16) -0.04774229171999877\n",
      "(7, 17) 0.24276601129358252\n",
      "(7, 18) -0.12460946892112189\n",
      "(7, 19) -0.15337469472243015\n",
      "(8, 0) -0.05240558809127548\n",
      "(8, 1) -0.17647696410882927\n",
      "(8, 2) -0.13790418793568904\n",
      "(8, 3) 0.08688909640675034\n",
      "(8, 4) -0.13711927016046843\n",
      "(8, 5) -0.21332804474027964\n",
      "(8, 6) -0.15726957975914502\n",
      "(8, 7) -0.0522012396420024\n",
      "(8, 8) -0.06703269019858737\n",
      "(8, 9) 0.06566276620212363\n",
      "(8, 10) 0.1828962289174285\n",
      "(8, 11) 0.14768379683616217\n",
      "(8, 12) -0.21169437256496335\n",
      "(8, 13) 0.19553280643513912\n",
      "(8, 14) -0.023919848057829537\n",
      "(8, 15) 0.13526134834407344\n",
      "(8, 16) -0.003500868483996555\n",
      "(8, 17) 0.23309497549917066\n",
      "(8, 18) -0.053539509359268316\n",
      "(8, 19) 0.11285821526207938\n",
      "(9, 0) -0.00622241493886122\n",
      "(9, 1) 0.2550468236162118\n",
      "(9, 2) 0.16109338365488668\n",
      "(9, 3) 0.13244075658391807\n",
      "(9, 4) -0.005922917090117607\n",
      "(9, 5) -0.11511118618301451\n",
      "(9, 6) 0.048894889603801055\n",
      "(9, 7) 0.12655863899091457\n",
      "(9, 8) -0.255574652641144\n",
      "(9, 9) 0.21358080428690582\n",
      "(9, 10) 0.06261840383992023\n",
      "(9, 11) -0.02369930007795062\n",
      "(9, 12) 0.007825147374518338\n",
      "(9, 13) 0.018316030292453434\n",
      "(9, 14) -0.29140265018767764\n",
      "(9, 15) 0.19313190056102766\n",
      "(9, 16) 0.15642985129460385\n",
      "(9, 17) -0.07220022815168647\n",
      "(9, 18) 0.023954255290448142\n",
      "(9, 19) -0.03855159413923559\n",
      "(10, 0) 0.1968527216344995\n",
      "(10, 1) -0.06610332308198963\n",
      "(10, 2) 0.02790227870974604\n",
      "(10, 3) 0.03827780798992819\n",
      "(10, 4) 0.08156647037793618\n",
      "(10, 5) 0.10862762800378788\n",
      "(10, 6) -0.04929589172419923\n",
      "(10, 7) 0.23276588203557932\n",
      "(10, 8) -0.05137686924783224\n",
      "(10, 9) 0.0688244327751164\n",
      "(10, 10) 0.10350398071956589\n",
      "(10, 11) -0.2925684403187745\n",
      "(10, 12) 0.007287280290313446\n",
      "(10, 13) 0.1880268720277911\n",
      "(10, 14) 0.053051475923382434\n",
      "(10, 15) -0.036110894185981124\n",
      "(10, 16) -0.2654016648673263\n",
      "(10, 17) -0.018168132331908282\n",
      "(10, 18) 0.1095015648822084\n",
      "(10, 19) 0.19433789533174203\n",
      "(11, 0) 0.02172298310121334\n",
      "(11, 1) 0.03112411159911232\n",
      "(11, 2) -0.1289950437577403\n",
      "(11, 3) -0.006905935778789284\n",
      "(11, 4) -0.06048434535443902\n",
      "(11, 5) -0.45447049683566826\n",
      "(11, 6) -0.11581060670451392\n",
      "(11, 7) -0.1433455519617155\n",
      "(11, 8) 0.06819559579263057\n",
      "(11, 9) -0.0408096769710653\n",
      "(11, 10) 0.3841951031979817\n",
      "(11, 11) -0.12026612514759448\n",
      "(11, 12) -0.05691646070005162\n",
      "(11, 13) 0.03460396853505188\n",
      "(11, 14) 0.3836874299167902\n",
      "(11, 15) 0.020057476435297872\n",
      "(11, 16) -0.08024223840941147\n",
      "(11, 17) 0.1182310256808705\n",
      "(11, 18) 0.14792190552448403\n",
      "(11, 19) -0.1352889522632239\n",
      "(12, 0) 0.2866239027010664\n",
      "(12, 1) 0.06054677244016204\n",
      "(12, 2) 0.2119589740168237\n",
      "(12, 3) 0.05814848305085717\n",
      "(12, 4) -0.12455876721162439\n",
      "(12, 5) -0.031689058044293006\n",
      "(12, 6) 0.1142524859165661\n",
      "(12, 7) 0.11272033226816801\n",
      "(12, 8) -0.05023916287427709\n",
      "(12, 9) 0.1471790621820901\n",
      "(12, 10) 0.17727768999442614\n",
      "(12, 11) -0.1268805586818189\n",
      "(12, 12) 0.030352487634388577\n",
      "(12, 13) 0.16131106370664838\n",
      "(12, 14) 0.0013201810311613826\n",
      "(12, 15) -0.3888032164667265\n",
      "(12, 16) 0.010302876596313126\n",
      "(12, 17) 0.2014959139096106\n",
      "(12, 18) -0.013911384355580479\n",
      "(12, 19) -0.05134341054535695\n",
      "(13, 0) -0.206907814037649\n",
      "(13, 1) 0.11193703963741085\n",
      "(13, 2) -0.17313475728641944\n",
      "(13, 3) 0.1501853418961474\n",
      "(13, 4) -0.05106015992240031\n",
      "(13, 5) -0.07705316082962099\n",
      "(13, 6) 0.035623455074684784\n",
      "(13, 7) 0.2984088729895973\n",
      "(13, 8) -0.09775054872207532\n",
      "(13, 9) 0.051146531543366784\n",
      "(13, 10) 0.1534718393703116\n",
      "(13, 11) 0.16706158576518249\n",
      "(13, 12) 0.09182323328360552\n",
      "(13, 13) -0.15325657205522702\n",
      "(13, 14) 0.13460902090756122\n",
      "(13, 15) -0.0012808579530343422\n",
      "(13, 16) -0.07020714805072714\n",
      "(13, 17) 0.12773689199718774\n",
      "(13, 18) -0.18259294840561321\n",
      "(13, 19) -0.03364556175888822\n",
      "(14, 0) 0.13960576108473788\n",
      "(14, 1) 0.027179604256133413\n",
      "(14, 2) 0.1505578002714003\n",
      "(14, 3) -0.3333380255376994\n",
      "(14, 4) -0.29898611022538546\n",
      "(14, 5) -0.0070252875961074315\n",
      "(14, 6) 0.04396430473008194\n",
      "(14, 7) 0.0761906308710536\n",
      "(14, 8) 0.05859782792327905\n",
      "(14, 9) -0.0792263421089956\n",
      "(14, 10) 0.09254425896720873\n",
      "(14, 11) 0.053413611134089926\n",
      "(14, 12) 0.03065846954086737\n",
      "(14, 13) 0.28694209106561175\n",
      "(14, 14) 0.06682053843576341\n",
      "(14, 15) -0.10920401880554208\n",
      "(14, 16) -0.020483125551251646\n",
      "(14, 17) 0.19100152295337122\n",
      "(14, 18) 0.047526577429124466\n",
      "(14, 19) 0.010750914425372569\n",
      "W1 relative error: 1.00e+00\n",
      "(0, 0) 0.048476209890679904\n",
      "(0, 1) 0.1856276381051458\n",
      "(0, 2) -0.0032823044726626445\n",
      "(0, 3) -0.1970041844767678\n",
      "(0, 4) 0.006380806771844049\n",
      "(0, 5) -0.28213195899517984\n",
      "(0, 6) -0.000365232111221303\n",
      "(0, 7) -0.14393175069571384\n",
      "(0, 8) 0.015578336753918618\n",
      "(0, 9) 0.10002420642862829\n",
      "(0, 10) 0.06654645474668541\n",
      "(0, 11) 0.16741050767876686\n",
      "(0, 12) -0.030177524301677746\n",
      "(0, 13) -0.012678842775670772\n",
      "(0, 14) 0.02528504499110795\n",
      "(0, 15) 0.09331778350052387\n",
      "(0, 16) 0.1355506515920979\n",
      "(0, 17) -0.25201974565014496\n",
      "(0, 18) -0.1505007246827006\n",
      "(0, 19) -0.09784624435127397\n",
      "(0, 20) -0.30870729421650367\n",
      "(0, 21) 0.030521418770135252\n",
      "(0, 22) -0.06353520385360412\n",
      "(0, 23) -0.12698178730730092\n",
      "(0, 24) -0.01283236588101033\n",
      "(0, 25) 0.29260404588171696\n",
      "(0, 26) 0.10101249285909829\n",
      "(0, 27) 0.45611972492309855\n",
      "(0, 28) -0.02839021924216922\n",
      "(0, 29) 0.019199693879201618\n",
      "(1, 0) -0.2258392059140135\n",
      "(1, 1) -0.05618544935970248\n",
      "(1, 2) -0.006175938382924072\n",
      "(1, 3) 0.16399509625841802\n",
      "(1, 4) 0.1340812978867234\n",
      "(1, 5) -0.1063669444079096\n",
      "(1, 6) -0.011388432774595001\n",
      "(1, 7) 0.02470145643584942\n",
      "(1, 8) -0.09611060032277406\n",
      "(1, 9) 0.03093985809776711\n",
      "(1, 10) -0.12788183858525315\n",
      "(1, 11) -0.013806299659080421\n",
      "(1, 12) -0.14520313209587243\n",
      "(1, 13) -0.2532588738279884\n",
      "(1, 14) 0.23747554056541273\n",
      "(1, 15) 0.3090019395912691\n",
      "(1, 16) -0.05388588704136054\n",
      "(1, 17) -0.011345051786904035\n",
      "(1, 18) -0.09660631823393827\n",
      "(1, 19) -0.09690601130429853\n",
      "(1, 20) 0.03686029312888195\n",
      "(1, 21) 0.42754142079992613\n",
      "(1, 22) 0.09846350788045298\n",
      "(1, 23) -0.0936196125955746\n",
      "(1, 24) -0.18960251120248015\n",
      "(1, 25) 0.0033208563454678592\n",
      "(1, 26) -0.12618199445313394\n",
      "(1, 27) 0.5613187360253846\n",
      "(1, 28) 0.274819060397391\n",
      "(1, 29) -0.23803611766126662\n",
      "(2, 0) -0.08567610985110717\n",
      "(2, 1) -0.08289540138761708\n",
      "(2, 2) 0.2321274634731196\n",
      "(2, 3) -0.013595369097174624\n",
      "(2, 4) -0.014083277966037143\n",
      "(2, 5) 0.15673320472586738\n",
      "(2, 6) 0.12303052612239183\n",
      "(2, 7) 0.153644097888872\n",
      "(2, 8) -0.06015060294295437\n",
      "(2, 9) -0.09111097925007526\n",
      "(2, 10) -0.22521079476867098\n",
      "(2, 11) 0.11987356494103095\n",
      "(2, 12) 0.0577269034351957\n",
      "(2, 13) 0.020819862500687236\n",
      "(2, 14) 0.26746136980726476\n",
      "(2, 15) 0.15402392929964037\n",
      "(2, 16) 0.031196995609050756\n",
      "(2, 17) -0.06553707607714898\n",
      "(2, 18) -0.22413842004631587\n",
      "(2, 19) 0.07073259160605971\n",
      "(2, 20) -0.3516932391089966\n",
      "(2, 21) -0.20364870545463984\n",
      "(2, 22) 0.01772135163058408\n",
      "(2, 23) -0.20609174389285553\n",
      "(2, 24) -0.170277248523476\n",
      "(2, 25) -0.04904904784552854\n",
      "(2, 26) 0.001377840197491764\n",
      "(2, 27) -0.5000047913483741\n",
      "(2, 28) 0.24861476028981142\n",
      "(2, 29) 0.28541654151226226\n",
      "(3, 0) 0.011481791784007099\n",
      "(3, 1) 0.05179735853566569\n",
      "(3, 2) 0.18326503932186708\n",
      "(3, 3) 0.29206479226218107\n",
      "(3, 4) 0.15273419959882517\n",
      "(3, 5) -0.14016055307486397\n",
      "(3, 6) 0.037308868883201285\n",
      "(3, 7) -0.07557551220394032\n",
      "(3, 8) 0.05899006580989407\n",
      "(3, 9) 0.020384333287992717\n",
      "(3, 10) 0.25914241215119205\n",
      "(3, 11) 0.11388245741983381\n",
      "(3, 12) -0.16183974196337658\n",
      "(3, 13) -0.3228952311751243\n",
      "(3, 14) 0.11683544145490997\n",
      "(3, 15) 0.08615458817473608\n",
      "(3, 16) 0.2174081336292488\n",
      "(3, 17) -0.07922715163921623\n",
      "(3, 18) 0.02509759728930305\n",
      "(3, 19) 0.014022262240231951\n",
      "(3, 20) -0.041929345595548284\n",
      "(3, 21) 0.05250579500071239\n",
      "(3, 22) -0.09782355645526762\n",
      "(3, 23) 0.15677488915954996\n",
      "(3, 24) 0.12943356768602143\n",
      "(3, 25) -0.04465394867203542\n",
      "(3, 26) 0.08147785361956039\n",
      "(3, 27) -0.7153953738736617\n",
      "(3, 28) 0.08195068361693814\n",
      "(3, 29) -0.019309071408457612\n",
      "(4, 0) 0.023527061054906536\n",
      "(4, 1) 0.11983466259302132\n",
      "(4, 2) -0.1300816538929439\n",
      "(4, 3) -0.14455464008023\n",
      "(4, 4) -0.032560447005280935\n",
      "(4, 5) 0.0531701594752576\n",
      "(4, 6) 0.004630488792400911\n",
      "(4, 7) 0.1394168259505335\n",
      "(4, 8) -0.03324209902899611\n",
      "(4, 9) -0.012259005410797384\n",
      "(4, 10) -0.22668927419644544\n",
      "(4, 11) 0.21522429669573737\n",
      "(4, 12) -0.07863749518222107\n",
      "(4, 13) 0.08262423616400838\n",
      "(4, 14) 0.07282488425630618\n",
      "(4, 15) -0.06101127234536818\n",
      "(4, 16) 0.0708567665874682\n",
      "(4, 17) -0.14368727239144619\n",
      "(4, 18) 0.21326470216465052\n",
      "(4, 19) -0.15129088444254535\n",
      "(4, 20) 0.046643582241046026\n",
      "(4, 21) -0.11432411191059087\n",
      "(4, 22) 0.006050371803567599\n",
      "(4, 23) 0.0476411063488058\n",
      "(4, 24) 0.06717463723049377\n",
      "(4, 25) 0.2360966492975791\n",
      "(4, 26) 0.2295522034678754\n",
      "(4, 27) 0.6150337642729653\n",
      "(4, 28) 0.01020112643246307\n",
      "(4, 29) 0.017231805848894055\n",
      "(5, 0) -0.007760288989189234\n",
      "(5, 1) -0.15242884208177543\n",
      "(5, 2) 0.13476732139139358\n",
      "(5, 3) 0.1732108870111659\n",
      "(5, 4) 0.08293600912701038\n",
      "(5, 5) -0.2567221126348329\n",
      "(5, 6) -0.09380378007683986\n",
      "(5, 7) -0.07510772621621697\n",
      "(5, 8) 0.3739265848956563\n",
      "(5, 9) -0.1581272738970796\n",
      "(5, 10) 0.1205838007223292\n",
      "(5, 11) 0.06406705317374417\n",
      "(5, 12) -0.09987217528539814\n",
      "(5, 13) -0.0500961044203052\n",
      "(5, 14) -0.029354084096766538\n",
      "(5, 15) -0.15504428869661524\n",
      "(5, 16) -0.003137093118610323\n",
      "(5, 17) 0.07498580369968977\n",
      "(5, 18) 0.35623012690777495\n",
      "(5, 19) -0.190884922890433\n",
      "(5, 20) 0.20640892177681278\n",
      "(5, 21) 0.14810940980325427\n",
      "(5, 22) -0.23266941093780244\n",
      "(5, 23) 0.08803165671977807\n",
      "(5, 24) 0.13457475698253063\n",
      "(5, 25) -0.22977362328369108\n",
      "(5, 26) -0.22660506040494963\n",
      "(5, 27) -0.6398999061740795\n",
      "(5, 28) -0.07843024407705457\n",
      "(5, 29) -0.04237088950809209\n",
      "(6, 0) -0.18241652304240571\n",
      "(6, 1) 0.024661853803564778\n",
      "(6, 2) -0.06750884269379753\n",
      "(6, 3) 0.31773236131016347\n",
      "(6, 4) -0.04646221207771361\n",
      "(6, 5) 0.16065979311363776\n",
      "(6, 6) 0.11926059104716556\n",
      "(6, 7) -0.017906038429771343\n",
      "(6, 8) 0.13198628465715956\n",
      "(6, 9) 0.017751240521945988\n",
      "(6, 10) -0.0009255246791184389\n",
      "(6, 11) 0.03646892636766097\n",
      "(6, 12) 0.23696971247488816\n",
      "(6, 13) 0.14782127082391128\n",
      "(6, 14) 0.06454295036206759\n",
      "(6, 15) -0.019285589969442185\n",
      "(6, 16) -0.08472468779885389\n",
      "(6, 17) 0.038004500746424696\n",
      "(6, 18) -0.22857575885382173\n",
      "(6, 19) 0.11333878817687547\n",
      "(6, 20) -0.1810036012628302\n",
      "(6, 21) 0.04080883462265206\n",
      "(6, 22) 0.05028502823023472\n",
      "(6, 23) -0.12220567051635099\n",
      "(6, 24) 0.051199502326682016\n",
      "(6, 25) -0.17590896028707445\n",
      "(6, 26) 0.006223347348566221\n",
      "(6, 27) 0.6851366596283269\n",
      "(6, 28) -0.14675012818265998\n",
      "(6, 29) 0.13369271281149508\n",
      "(7, 0) -0.35332726655568075\n",
      "(7, 1) -0.02243168637505732\n",
      "(7, 2) -0.0696125976418216\n",
      "(7, 3) 0.14535289842854127\n",
      "(7, 4) 0.021442949682537456\n",
      "(7, 5) -0.2159523596834134\n",
      "(7, 6) -0.1023738348759906\n",
      "(7, 7) 0.17222467114663684\n",
      "(7, 8) -0.057026629862733096\n",
      "(7, 9) -0.07436395046411803\n",
      "(7, 10) 0.08052922892964887\n",
      "(7, 11) 0.063571519026695\n",
      "(7, 12) 0.016322890861175665\n",
      "(7, 13) 0.12602969698960464\n",
      "(7, 14) -0.4552840084048881\n",
      "(7, 15) 0.006237747607329424\n",
      "(7, 16) -0.019844725729356583\n",
      "(7, 17) 0.14414399158724223\n",
      "(7, 18) -0.3571498664811656\n",
      "(7, 19) -0.10788429158914424\n",
      "(7, 20) 0.12283773935806151\n",
      "(7, 21) 0.22337742189293405\n",
      "(7, 22) 0.033249591968598224\n",
      "(7, 23) 0.1482218322301776\n",
      "(7, 24) -0.08876015709091688\n",
      "(7, 25) -0.1283404708729563\n",
      "(7, 26) 0.12878641917346556\n",
      "(7, 27) -0.6165279376801891\n",
      "(7, 28) 0.19985093286933872\n",
      "(7, 29) 0.022309918623619748\n",
      "(8, 0) 0.18264859997785263\n",
      "(8, 1) 0.04297317537371725\n",
      "(8, 2) -0.08529118327160744\n",
      "(8, 3) -0.08255116044075805\n",
      "(8, 4) 0.012385781555934726\n",
      "(8, 5) 0.10808083601432371\n",
      "(8, 6) 0.20122587267579203\n",
      "(8, 7) 0.10119103950323448\n",
      "(8, 8) 0.06424367504642703\n",
      "(8, 9) 0.1692025107580264\n",
      "(8, 10) 0.15203762169235802\n",
      "(8, 11) -0.13248565409185176\n",
      "(8, 12) 0.06289126144309876\n",
      "(8, 13) -0.06588137919649739\n",
      "(8, 14) -0.14350835058074551\n",
      "(8, 15) -0.03770164087590899\n",
      "(8, 16) 0.040055607186673114\n",
      "(8, 17) 0.04331982976779613\n",
      "(8, 18) 0.000718317716419392\n",
      "(8, 19) 0.2526002558234097\n",
      "(8, 20) -0.178859527366626\n",
      "(8, 21) 0.5374183260631327\n",
      "(8, 22) 0.05476976911999997\n",
      "(8, 23) 0.13805259073684795\n",
      "(8, 24) 0.1342505190127241\n",
      "(8, 25) -0.014652222146693815\n",
      "(8, 26) -0.052490209911937306\n",
      "(8, 27) -0.3355777663749393\n",
      "(8, 28) 0.10777378705029149\n",
      "(8, 29) 0.026268102493176567\n",
      "(9, 0) 0.07080275330473285\n",
      "(9, 1) -0.05253259174331503\n",
      "(9, 2) 0.16778763169966737\n",
      "(9, 3) 0.09650964463148169\n",
      "(9, 4) 0.2593316944743407\n",
      "(9, 5) -0.10436813093761542\n",
      "(9, 6) -0.09670939511430275\n",
      "(9, 7) -0.045856273800382034\n",
      "(9, 8) 0.2835161086345295\n",
      "(9, 9) -0.10495967011081574\n",
      "(9, 10) 0.08610692678878705\n",
      "(9, 11) -0.10627181068478818\n",
      "(9, 12) -0.22031870243743865\n",
      "(9, 13) -0.1809518402229315\n",
      "(9, 14) -0.15492144864737156\n",
      "(9, 15) -0.0033838916113637647\n",
      "(9, 16) 0.45917918445326217\n",
      "(9, 17) -0.06969301118431304\n",
      "(9, 18) 0.07994865875993185\n",
      "(9, 19) -0.0615838355866316\n",
      "(9, 20) -0.07603032079472882\n",
      "(9, 21) -0.12004764693429591\n",
      "(9, 22) 0.2470028149126335\n",
      "(9, 23) -0.16407568099729986\n",
      "(9, 24) -0.13578776503209156\n",
      "(9, 25) -0.15053453297220187\n",
      "(9, 26) -0.07399033972177449\n",
      "(9, 27) 0.4548276626437086\n",
      "(9, 28) 0.00601480705242352\n",
      "(9, 29) -0.1644588141225256\n",
      "(10, 0) 0.10069123765887865\n",
      "(10, 1) -0.04790907697227453\n",
      "(10, 2) 0.2807982014463306\n",
      "(10, 3) 0.2092656576913043\n",
      "(10, 4) -0.009818861190780126\n",
      "(10, 5) 0.2112446172208848\n",
      "(10, 6) -0.021592550369931015\n",
      "(10, 7) -0.16248547658470613\n",
      "(10, 8) 0.07745562062844158\n",
      "(10, 9) 0.15406798850037262\n",
      "(10, 10) -0.1455026503727197\n",
      "(10, 11) -0.11718328059018289\n",
      "(10, 12) 0.0924867814777741\n",
      "(10, 13) -0.031695353719385366\n",
      "(10, 14) 0.24346776683614732\n",
      "(10, 15) -0.27434261542502725\n",
      "(10, 16) -0.06855199572441961\n",
      "(10, 17) 0.235696757711068\n",
      "(10, 18) 0.043584957287734476\n",
      "(10, 19) 0.010222829960326862\n",
      "(10, 20) 0.24086078882490367\n",
      "(10, 21) -0.011086347750932644\n",
      "(10, 22) 0.027298854909929556\n",
      "(10, 23) -0.16533997646561716\n",
      "(10, 24) 0.09749037919171143\n",
      "(10, 25) 0.10753546226816012\n",
      "(10, 26) -0.19900904453251653\n",
      "(10, 27) 0.7792665452921453\n",
      "(10, 28) -0.026988559165275202\n",
      "(10, 29) -0.05936392737382334\n",
      "(11, 0) 0.02779874845870722\n",
      "(11, 1) 0.12647713161229035\n",
      "(11, 2) -0.2263067958807596\n",
      "(11, 3) -0.09226037462894963\n",
      "(11, 4) 0.12208901449817232\n",
      "(11, 5) -0.06826293397210748\n",
      "(11, 6) -0.280362546378754\n",
      "(11, 7) -0.04623658469427027\n",
      "(11, 8) 0.2249890973526902\n",
      "(11, 9) 0.006939799224170428\n",
      "(11, 10) 0.04845935661634825\n",
      "(11, 11) 0.13470319495390015\n",
      "(11, 12) -0.08294567170885614\n",
      "(11, 13) 0.07107596102784441\n",
      "(11, 14) -0.08683213268412258\n",
      "(11, 15) -0.06506138117146065\n",
      "(11, 16) 0.034044402008603925\n",
      "(11, 17) -0.07745266565883924\n",
      "(11, 18) -0.22464978033376323\n",
      "(11, 19) 0.20726001759285848\n",
      "(11, 20) -0.18525077458697578\n",
      "(11, 21) 0.07770769476778128\n",
      "(11, 22) 0.21800663296822617\n",
      "(11, 23) -0.2546422171789686\n",
      "(11, 24) 0.21666862579650112\n",
      "(11, 25) 0.08762736487533117\n",
      "(11, 26) 0.3504697761336217\n",
      "(11, 27) 0.503734228285424\n",
      "(11, 28) -0.003562065220563681\n",
      "(11, 29) 0.05880470235197776\n",
      "(12, 0) 0.1069930386954354\n",
      "(12, 1) 0.16273899889895915\n",
      "(12, 2) 0.14541721822247666\n",
      "(12, 3) -0.13227772264201576\n",
      "(12, 4) 0.4435828486748505\n",
      "(12, 5) 0.0970749927997616\n",
      "(12, 6) 0.10257021427761968\n",
      "(12, 7) -0.06559518404003484\n",
      "(12, 8) 0.21534464740291523\n",
      "(12, 9) 0.0953118666657815\n",
      "(12, 10) 0.010592752630600444\n",
      "(12, 11) 0.1958602283913535\n",
      "(12, 12) -0.1832902342790987\n",
      "(12, 13) 0.30694830446265087\n",
      "(12, 14) -0.017222865000832144\n",
      "(12, 15) 0.19549723515588366\n",
      "(12, 16) 0.09591235823336318\n",
      "(12, 17) 0.1257476020199988\n",
      "(12, 18) -0.08096976849003568\n",
      "(12, 19) 0.04392279233655926\n",
      "(12, 20) 0.040764518294267305\n",
      "(12, 21) -0.3423725026596713\n",
      "(12, 22) -0.17017521019013768\n",
      "(12, 23) 0.009475918361090407\n",
      "(12, 24) -0.1552010608474319\n",
      "(12, 25) 0.3025195968842098\n",
      "(12, 26) 0.025156891947375467\n",
      "(12, 27) 0.1383988633030242\n",
      "(12, 28) 0.1915905024851838\n",
      "(12, 29) 0.02285212792330071\n",
      "(13, 0) -0.2125121712381883\n",
      "(13, 1) 0.047685187087864726\n",
      "(13, 2) -0.03452359442768227\n",
      "(13, 3) -0.062389636568127564\n",
      "(13, 4) -0.25396968967861255\n",
      "(13, 5) -0.4501969429249186\n",
      "(13, 6) 0.021598994726090833\n",
      "(13, 7) -0.041518832238907066\n",
      "(13, 8) 0.027214384523688292\n",
      "(13, 9) -0.14477925169842365\n",
      "(13, 10) -0.05688975890372205\n",
      "(13, 11) -0.3714789388098438\n",
      "(13, 12) 0.2723394349590791\n",
      "(13, 13) -0.07698332860073265\n",
      "(13, 14) 0.07077855621595575\n",
      "(13, 15) -0.16395373663158352\n",
      "(13, 16) 0.27909702717821006\n",
      "(13, 17) 0.08259318926562287\n",
      "(13, 18) -0.122766685928255\n",
      "(13, 19) 0.16914789542354924\n",
      "(13, 20) 0.016045437067901958\n",
      "(13, 21) 0.09758646379864898\n",
      "(13, 22) 0.13258293405371546\n",
      "(13, 23) 0.08906348329951184\n",
      "(13, 24) -0.005871233410559284\n",
      "(13, 25) 0.560189032094982\n",
      "(13, 26) -0.03186801365018255\n",
      "(13, 27) -0.6309647367253035\n",
      "(13, 28) 0.07413570264347413\n",
      "(13, 29) -0.035015748789390955\n",
      "(14, 0) 0.17221551451562786\n",
      "(14, 1) -0.2628286629224874\n",
      "(14, 2) 0.10911256715928629\n",
      "(14, 3) 0.30462770248540494\n",
      "(14, 4) 0.04319172139943816\n",
      "(14, 5) 0.1642077326557967\n",
      "(14, 6) 0.18780377479821195\n",
      "(14, 7) -0.125867901390464\n",
      "(14, 8) -0.04330049048206774\n",
      "(14, 9) 0.37714638199126677\n",
      "(14, 10) 0.05851270872270219\n",
      "(14, 11) 0.20314303794677355\n",
      "(14, 12) 0.04290814854535085\n",
      "(14, 13) -0.1440502321425896\n",
      "(14, 14) 0.28337640429754174\n",
      "(14, 15) -0.28772976037316766\n",
      "(14, 16) 0.14305373703393798\n",
      "(14, 17) -0.1582870662097946\n",
      "(14, 18) -0.10404832502253213\n",
      "(14, 19) -0.10464432795842525\n",
      "(14, 20) -0.013466958126429061\n",
      "(14, 21) 0.1558207537666334\n",
      "(14, 22) 0.11694018420271844\n",
      "(14, 23) -0.013052121961010242\n",
      "(14, 24) -0.06232342708578641\n",
      "(14, 25) -0.1023629864871367\n",
      "(14, 26) -0.0393464911763175\n",
      "(14, 27) -0.7991047124455973\n",
      "(14, 28) 0.008791202921187846\n",
      "(14, 29) -0.19994353639418702\n",
      "(15, 0) 0.06777098762178468\n",
      "(15, 1) -0.047079444609465775\n",
      "(15, 2) 0.09714247157788235\n",
      "(15, 3) -0.2158780805672222\n",
      "(15, 4) 0.05077011575593814\n",
      "(15, 5) -0.219747437046891\n",
      "(15, 6) -0.1065634575692087\n",
      "(15, 7) 0.31514500768992093\n",
      "(15, 8) -0.1734558125576768\n",
      "(15, 9) -0.2683888888022068\n",
      "(15, 10) -0.3579249326257638\n",
      "(15, 11) -0.13269373129176643\n",
      "(15, 12) 0.01816821075806274\n",
      "(15, 13) -0.05758765633245843\n",
      "(15, 14) -0.00689760346617163\n",
      "(15, 15) 0.11865925477749782\n",
      "(15, 16) 0.09219367438362268\n",
      "(15, 17) 0.01836091403362161\n",
      "(15, 18) 0.03855206838210279\n",
      "(15, 19) 0.026304277067623612\n",
      "(15, 20) 0.009765719610754786\n",
      "(15, 21) 0.023728690567992313\n",
      "(15, 22) -0.09094631812089914\n",
      "(15, 23) -0.19073051356066625\n",
      "(15, 24) 0.16751044746854404\n",
      "(15, 25) 0.030570395415097092\n",
      "(15, 26) -0.037987214218659915\n",
      "(15, 27) 0.405195233943445\n",
      "(15, 28) 0.004494987182468435\n",
      "(15, 29) -0.01296047100751707\n",
      "(16, 0) 0.051232472930706756\n",
      "(16, 1) -0.01347344804614181\n",
      "(16, 2) 0.1321498426243295\n",
      "(16, 3) 0.03740674121566201\n",
      "(16, 4) -0.06482038790167621\n",
      "(16, 5) -0.06486619228418533\n",
      "(16, 6) 0.02022557721303997\n",
      "(16, 7) 0.03245408435326169\n",
      "(16, 8) -0.1370003246847773\n",
      "(16, 9) 0.1115914406657481\n",
      "(16, 10) 0.04005588563060769\n",
      "(16, 11) -0.014498480416236246\n",
      "(16, 12) -0.07591546986596143\n",
      "(16, 13) 0.05148415387346005\n",
      "(16, 14) 0.22673014399288147\n",
      "(16, 15) 0.1520536471399936\n",
      "(16, 16) 0.056959428551550666\n",
      "(16, 17) -0.12981200012696092\n",
      "(16, 18) -0.18155206702452628\n",
      "(16, 19) 0.1387636905825218\n",
      "(16, 20) 0.007495396392442898\n",
      "(16, 21) 0.10099458380707914\n",
      "(16, 22) 0.23273212947927388\n",
      "(16, 23) 0.11954836449667992\n",
      "(16, 24) 0.1315435466775483\n",
      "(16, 25) -0.11838847120415606\n",
      "(16, 26) 0.08947469387621253\n",
      "(16, 27) 0.26662236729535493\n",
      "(16, 28) 0.03373823060925929\n",
      "(16, 29) -0.16493470504919117\n",
      "(17, 0) -0.3083291590932902\n",
      "(17, 1) -0.1905593178808118\n",
      "(17, 2) 0.07109793553894406\n",
      "(17, 3) 0.14559963648075325\n",
      "(17, 4) -0.2941714709159271\n",
      "(17, 5) 0.22328471129817726\n",
      "(17, 6) 0.2860432312346006\n",
      "(17, 7) 0.27114309681941506\n",
      "(17, 8) -0.25210000988984405\n",
      "(17, 9) -0.060466730422703556\n",
      "(17, 10) -0.14439393920540056\n",
      "(17, 11) 0.19265513637733986\n",
      "(17, 12) 0.03597643045694099\n",
      "(17, 13) 0.12484642160082159\n",
      "(17, 14) -0.11023003079202452\n",
      "(17, 15) 0.04899184631312891\n",
      "(17, 16) 0.2119109753451198\n",
      "(17, 17) 0.2372914704729112\n",
      "(17, 18) 0.16894815728640822\n",
      "(17, 19) 0.14918858628476528\n",
      "(17, 20) 0.34522039280560074\n",
      "(17, 21) -0.1385588087821077\n",
      "(17, 22) -0.03840881488414993\n",
      "(17, 23) -0.1131849129087925\n",
      "(17, 24) 0.4366040783132518\n",
      "(17, 25) -0.06323148360465325\n",
      "(17, 26) 0.012467700916118927\n",
      "(17, 27) -0.5839865004020339\n",
      "(17, 28) 0.21148712852081528\n",
      "(17, 29) -0.2544307130758483\n",
      "(18, 0) 0.12515466605300674\n",
      "(18, 1) 0.07692863333019773\n",
      "(18, 2) 0.1683357981008271\n",
      "(18, 3) -0.1296796777960907\n",
      "(18, 4) -0.10316888059413996\n",
      "(18, 5) 0.24040009622972033\n",
      "(18, 6) -0.024595897896162452\n",
      "(18, 7) -0.23271657898504824\n",
      "(18, 8) 0.16664495792184653\n",
      "(18, 9) -0.12547902610293704\n",
      "(18, 10) 0.34099334387249763\n",
      "(18, 11) 0.10392459608432601\n",
      "(18, 12) -0.020151195467832395\n",
      "(18, 13) -0.1674566492138041\n",
      "(18, 14) 0.02255304405451852\n",
      "(18, 15) -0.14287517107192116\n",
      "(18, 16) 0.1686118708210671\n",
      "(18, 17) -0.1684536250934343\n",
      "(18, 18) 0.19090035152657944\n",
      "(18, 19) -0.15545311873310652\n",
      "(18, 20) 0.035119919772341746\n",
      "(18, 21) -0.18154340266640642\n",
      "(18, 22) -0.057959703081422724\n",
      "(18, 23) 0.17043934268379243\n",
      "(18, 24) -0.2473106734512953\n",
      "(18, 25) -0.2734259957559715\n",
      "(18, 26) -0.3104684929144952\n",
      "(18, 27) 0.5489169805361627\n",
      "(18, 28) -0.024275630172709835\n",
      "(18, 29) -0.2744827798384364\n",
      "(19, 0) 0.17451957736724918\n",
      "(19, 1) 0.052653794124779545\n",
      "(19, 2) 0.16837653191714708\n",
      "(19, 3) -0.3603528064832772\n",
      "(19, 4) -0.2905324306912149\n",
      "(19, 5) 0.041795210314887754\n",
      "(19, 6) -0.2742857970972068\n",
      "(19, 7) 0.01811137302354382\n",
      "(19, 8) 0.04410349787598022\n",
      "(19, 9) 0.05053316316505629\n",
      "(19, 10) 0.037029090016460486\n",
      "(19, 11) 0.046292291333571704\n",
      "(19, 12) -0.07795787881903493\n",
      "(19, 13) -0.10096715605811822\n",
      "(19, 14) -0.2269210536809396\n",
      "(19, 15) 0.07768337977331896\n",
      "(19, 16) 0.22499484781945964\n",
      "(19, 17) 0.03350775030774855\n",
      "(19, 18) 0.3443010567760751\n",
      "(19, 19) -0.09484744305510161\n",
      "(19, 20) -0.12408854184187133\n",
      "(19, 21) -0.06384559858574335\n",
      "(19, 22) 0.08158409108283138\n",
      "(19, 23) -0.11252964329244718\n",
      "(19, 24) 0.2232859428019651\n",
      "(19, 25) 0.07248423323780173\n",
      "(19, 26) -0.026203859926354763\n",
      "(19, 27) 0.3672057888426394\n",
      "(19, 28) -0.06135843397814255\n",
      "(19, 29) -0.3553610896211978\n",
      "W2 relative error: 1.00e+00\n",
      "(0, 0) 0.02065716069310497\n",
      "(0, 1) 0.06667107959046348\n",
      "(0, 2) 0.2887852726729534\n",
      "(0, 3) -0.004506896278400063\n",
      "(0, 4) -0.028968259879746935\n",
      "(0, 5) -0.2789889262722056\n",
      "(0, 6) 0.02151608020639628\n",
      "(0, 7) -0.2661704781914409\n",
      "(0, 8) -0.15726070352606314\n",
      "(0, 9) -0.06714476961100502\n",
      "(1, 0) 0.02296574814764085\n",
      "(1, 1) 0.29959870064821814\n",
      "(1, 2) 0.18414672844357935\n",
      "(1, 3) -0.026818136911188614\n",
      "(1, 4) 0.053600013227850234\n",
      "(1, 5) -0.0346228357539502\n",
      "(1, 6) 0.03931768448595108\n",
      "(1, 7) 0.0219725604377885\n",
      "(1, 8) 0.07951107932058221\n",
      "(1, 9) 0.025518315549533096\n",
      "(2, 0) -0.033568358492885864\n",
      "(2, 1) -0.019205153600765357\n",
      "(2, 2) 0.17762485597927477\n",
      "(2, 3) -0.21570032293638516\n",
      "(2, 4) -0.2067159849516997\n",
      "(2, 5) -0.020665699107524915\n",
      "(2, 6) 0.2851051041030672\n",
      "(2, 7) 0.07240311741263383\n",
      "(2, 8) 0.03903391898596453\n",
      "(2, 9) 0.28568601417866546\n",
      "(3, 0) 0.08036236431863131\n",
      "(3, 1) -0.12926272403568362\n",
      "(3, 2) -0.07896418448005704\n",
      "(3, 3) -0.26326486595174003\n",
      "(3, 4) 0.08760902039384176\n",
      "(3, 5) -0.029548246072153003\n",
      "(3, 6) 0.21618394021594153\n",
      "(3, 7) -0.3446288761921323\n",
      "(3, 8) 0.04989397552890295\n",
      "(3, 9) 0.021631563829060948\n",
      "(4, 0) 0.20965163853858823\n",
      "(4, 1) 0.24417797614972866\n",
      "(4, 2) -0.13194504440150467\n",
      "(4, 3) -0.11582881049854164\n",
      "(4, 4) -0.06312944536013276\n",
      "(4, 5) 0.08064633654214504\n",
      "(4, 6) 0.06686731763849707\n",
      "(4, 7) 0.12875733119699362\n",
      "(4, 8) -0.027876048225294877\n",
      "(4, 9) 0.10230351361606436\n",
      "(5, 0) 0.003101936396632254\n",
      "(5, 1) 0.1496067326467454\n",
      "(5, 2) 0.22575776834621306\n",
      "(5, 3) -0.06317823721957438\n",
      "(5, 4) 0.1458417767441489\n",
      "(5, 5) -0.23456086810647034\n",
      "(5, 6) -0.27551721650809213\n",
      "(5, 7) -0.05431200089667242\n",
      "(5, 8) 0.09221295904637826\n",
      "(5, 9) -0.16654364678458933\n",
      "(6, 0) -0.023086654143966708\n",
      "(6, 1) -0.09310531101647256\n",
      "(6, 2) 0.192924615260992\n",
      "(6, 3) -0.31509518807482095\n",
      "(6, 4) -0.04029783826631217\n",
      "(6, 5) 0.10739517586344503\n",
      "(6, 6) -0.33111652268935643\n",
      "(6, 7) -0.3270805913224706\n",
      "(6, 8) 0.28234773763458065\n",
      "(6, 9) 0.25169863970830875\n",
      "(7, 0) 0.04402635580547098\n",
      "(7, 1) 0.06372610643623489\n",
      "(7, 2) -0.09118792956286369\n",
      "(7, 3) -0.14783092416870147\n",
      "(7, 4) 0.13162509708841696\n",
      "(7, 5) -0.3848458776545271\n",
      "(7, 6) -0.20176878270383722\n",
      "(7, 7) -0.31182940718466057\n",
      "(7, 8) -0.05847531325819943\n",
      "(7, 9) 0.2534741633919424\n",
      "(8, 0) 0.09600823860367312\n",
      "(8, 1) -0.1911279421396017\n",
      "(8, 2) 0.12793076180628304\n",
      "(8, 3) 0.17178752944602135\n",
      "(8, 4) 0.07914569293276941\n",
      "(8, 5) -0.29352051855724426\n",
      "(8, 6) -0.2397844649060232\n",
      "(8, 7) 0.25753732884048475\n",
      "(8, 8) 0.04197016854057267\n",
      "(8, 9) -0.026098969474475094\n",
      "(9, 0) 0.12602497108105126\n",
      "(9, 1) 0.04760367691147848\n",
      "(9, 2) 0.10528725171710106\n",
      "(9, 3) -0.21033684740601186\n",
      "(9, 4) -0.17129946088267897\n",
      "(9, 5) 0.1579260020090345\n",
      "(9, 6) 0.0034261346648634112\n",
      "(9, 7) -0.0676116446385322\n",
      "(9, 8) -0.18584105232477552\n",
      "(9, 9) 0.34132654045393446\n",
      "(10, 0) -0.0022697881352229388\n",
      "(10, 1) 0.12062523007116964\n",
      "(10, 2) -0.13373336811284275\n",
      "(10, 3) 0.21589516601139278\n",
      "(10, 4) -0.04571425420429875\n",
      "(10, 5) -0.14999080892863503\n",
      "(10, 6) -0.18237512553476162\n",
      "(10, 7) -0.5217698772153057\n",
      "(10, 8) 0.005427292837367758\n",
      "(10, 9) -0.03893817561717583\n",
      "(11, 0) -0.04529446697709715\n",
      "(11, 1) 0.037225101978677344\n",
      "(11, 2) 0.0277111512403394\n",
      "(11, 3) -0.08246803013811643\n",
      "(11, 4) 0.002351635197683777\n",
      "(11, 5) 0.1055124427384868\n",
      "(11, 6) 0.3571386318679259\n",
      "(11, 7) 0.0994208698035237\n",
      "(11, 8) -0.04840796150595849\n",
      "(11, 9) 0.016847364081584715\n",
      "(12, 0) -0.17393308371360658\n",
      "(12, 1) 0.15277770502031274\n",
      "(12, 2) 0.08322908207070157\n",
      "(12, 3) 0.07757173809963547\n",
      "(12, 4) 0.5238899976944822\n",
      "(12, 5) -0.1301692479138694\n",
      "(12, 6) -0.0841508618787401\n",
      "(12, 7) -0.20670850480186684\n",
      "(12, 8) 0.1567643676203545\n",
      "(12, 9) 0.14740617766406672\n",
      "(13, 0) 0.04264364528161479\n",
      "(13, 1) 0.04812580067792282\n",
      "(13, 2) 0.08458803719690877\n",
      "(13, 3) -0.2216680696776052\n",
      "(13, 4) -0.18605451268527415\n",
      "(13, 5) -0.0017461089463211008\n",
      "(13, 6) 0.39271744038948947\n",
      "(13, 7) 0.26738702540995973\n",
      "(13, 8) -0.10724095540481925\n",
      "(13, 9) -0.10128193608238688\n",
      "(14, 0) -0.07973606765965258\n",
      "(14, 1) -0.11160380020136527\n",
      "(14, 2) 0.019306464738022555\n",
      "(14, 3) -0.120699702987892\n",
      "(14, 4) 0.18078117931530355\n",
      "(14, 5) -0.31935404356531194\n",
      "(14, 6) -0.012225234558016494\n",
      "(14, 7) -0.1375808268644363\n",
      "(14, 8) 0.19505274573283768\n",
      "(14, 9) 0.2674272019831392\n",
      "(15, 0) 0.03798063956672593\n",
      "(15, 1) 0.0551473394949653\n",
      "(15, 2) 0.21771276017545912\n",
      "(15, 3) 0.06840313266920361\n",
      "(15, 4) -0.08998800629100855\n",
      "(15, 5) -0.12193157217232907\n",
      "(15, 6) 0.09273376493368345\n",
      "(15, 7) 0.2543446236735747\n",
      "(15, 8) 0.013693588618579609\n",
      "(15, 9) 0.12697912921133536\n",
      "(16, 0) 0.11109122901586942\n",
      "(16, 1) 0.03213979771210518\n",
      "(16, 2) 0.21113312942411253\n",
      "(16, 3) -0.21406647823241085\n",
      "(16, 4) 0.08740034584953092\n",
      "(16, 5) 0.11778616348934177\n",
      "(16, 6) 0.4023499363903226\n",
      "(16, 7) 0.28425132456710855\n",
      "(16, 8) -0.19370549351194197\n",
      "(16, 9) -0.051156891611725534\n",
      "(17, 0) -0.007455150674573473\n",
      "(17, 1) -0.1706243564658649\n",
      "(17, 2) 0.10277299407057681\n",
      "(17, 3) 0.28417076740616665\n",
      "(17, 4) 0.10671833425845988\n",
      "(17, 5) -0.3338256714613408\n",
      "(17, 6) -0.10168634956286836\n",
      "(17, 7) -0.7784912007036126\n",
      "(17, 8) 0.18145395537239037\n",
      "(17, 9) -0.15805220399123243\n",
      "(18, 0) -0.2899297590897021\n",
      "(18, 1) 0.15257903989152055\n",
      "(18, 2) -0.14506170309402933\n",
      "(18, 3) 0.03834378170530783\n",
      "(18, 4) 0.0053083466511338875\n",
      "(18, 5) -0.17649099244287922\n",
      "(18, 6) -0.08386952812244886\n",
      "(18, 7) 0.062173947235066855\n",
      "(18, 8) 0.02694387899460082\n",
      "(18, 9) -0.2882047374974661\n",
      "(19, 0) -0.0364374539874035\n",
      "(19, 1) -0.20702581258191796\n",
      "(19, 2) -0.05749732325810441\n",
      "(19, 3) -0.20017238191449846\n",
      "(19, 4) -0.029273437718302372\n",
      "(19, 5) 0.1619132424135472\n",
      "(19, 6) 0.2507721930111728\n",
      "(19, 7) -0.4006009577839364\n",
      "(19, 8) -0.12750162552421784\n",
      "(19, 9) 0.062043754578411374\n",
      "(20, 0) 0.3058093851926458\n",
      "(20, 1) 0.08498024737235708\n",
      "(20, 2) -0.02956788724972625\n",
      "(20, 3) -0.20239676024047523\n",
      "(20, 4) -0.048304701483203864\n",
      "(20, 5) -0.05453656650722393\n",
      "(20, 6) 0.08816815633139184\n",
      "(20, 7) -0.35804359836966165\n",
      "(20, 8) 0.027932277246733857\n",
      "(20, 9) 0.11317984114356248\n",
      "(21, 0) -0.08405514888565335\n",
      "(21, 1) -0.24262260813756595\n",
      "(21, 2) -0.16373306683803435\n",
      "(21, 3) 0.05500519928425262\n",
      "(21, 4) 0.061729560574264035\n",
      "(21, 5) 0.045248291202781836\n",
      "(21, 6) 0.13288430635860493\n",
      "(21, 7) -0.20028072644784342\n",
      "(21, 8) 0.07159306560922118\n",
      "(21, 9) 0.28263084042023934\n",
      "(22, 0) -0.1004327867981658\n",
      "(22, 1) 0.022980198233213397\n",
      "(22, 2) -0.03817962794805396\n",
      "(22, 3) 0.00894434437626046\n",
      "(22, 4) 0.22540729327502615\n",
      "(22, 5) 0.017530521834174806\n",
      "(22, 6) 0.07179449208472022\n",
      "(22, 7) 0.15682618554890837\n",
      "(22, 8) 0.042253030096972566\n",
      "(22, 9) 0.054376800573407984\n",
      "(23, 0) 0.059097760329862574\n",
      "(23, 1) 0.015392868935037994\n",
      "(23, 2) -0.03485424757698752\n",
      "(23, 3) -0.10596266761808691\n",
      "(23, 4) 0.18973388757892448\n",
      "(23, 5) -0.10707251587582788\n",
      "(23, 6) -0.003652143698573695\n",
      "(23, 7) -0.5078494623944607\n",
      "(23, 8) -0.05088236951777957\n",
      "(23, 9) 0.16013429418038072\n",
      "(24, 0) -0.0988312049976514\n",
      "(24, 1) 0.11070238947752385\n",
      "(24, 2) 0.05727226577434407\n",
      "(24, 3) 0.06777807937119462\n",
      "(24, 4) 0.2475583046113172\n",
      "(24, 5) 0.034689853478653276\n",
      "(24, 6) 0.25271261074877316\n",
      "(24, 7) -0.527580034637154\n",
      "(24, 8) 0.17940221446188784\n",
      "(24, 9) 0.2870071245997252\n",
      "(25, 0) -0.10956469016498714\n",
      "(25, 1) 0.007548821123748438\n",
      "(25, 2) 0.050147848984494196\n",
      "(25, 3) 0.05875085911100086\n",
      "(25, 4) 0.01004459204700936\n",
      "(25, 5) -0.09380986618623409\n",
      "(25, 6) -0.13717162827830975\n",
      "(25, 7) 0.17055375640673273\n",
      "(25, 8) 0.0833912452424812\n",
      "(25, 9) -0.22843400908634234\n",
      "(26, 0) -0.5004665575736311\n",
      "(26, 1) 0.16020499460367432\n",
      "(26, 2) -0.13196832537865077\n",
      "(26, 3) 0.25126099112426914\n",
      "(26, 4) -0.07062681004477156\n",
      "(26, 5) -0.09120031281284467\n",
      "(26, 6) -0.12314732305007679\n",
      "(26, 7) 0.08343261317378392\n",
      "(26, 8) -0.017683317699024315\n",
      "(26, 9) -0.06510248709012956\n",
      "(27, 0) -0.10239077044005283\n",
      "(27, 1) 0.3820157689737868\n",
      "(27, 2) 0.04380823872551786\n",
      "(27, 3) 0.034779274793450554\n",
      "(27, 4) 0.11238981372230226\n",
      "(27, 5) -0.14063346847059677\n",
      "(27, 6) -0.2785671347815821\n",
      "(27, 7) -0.21314791514015494\n",
      "(27, 8) 0.06470969169392049\n",
      "(27, 9) -0.161916499497039\n",
      "(28, 0) -0.056113844326688415\n",
      "(28, 1) -0.1101013848092691\n",
      "(28, 2) -0.151692144267912\n",
      "(28, 3) -0.007800836332449989\n",
      "(28, 4) -0.0463886915547107\n",
      "(28, 5) 0.2109591920707032\n",
      "(28, 6) 0.017412819630635568\n",
      "(28, 7) -0.5065315801466852\n",
      "(28, 8) 0.003765945821854188\n",
      "(28, 9) 0.2231929287610512\n",
      "(29, 0) -0.13876405389190438\n",
      "(29, 1) -0.07430361774751759\n",
      "(29, 2) 0.09149205490999178\n",
      "(29, 3) -0.2304088002169635\n",
      "(29, 4) 0.1670578043011517\n",
      "(29, 5) -0.014368531831010499\n",
      "(29, 6) 0.07168497373477578\n",
      "(29, 7) -0.43914107328291146\n",
      "(29, 8) 0.16665905366863853\n",
      "(29, 9) -0.11976746772113243\n",
      "W3 relative error: 7.00e-09\n",
      "(0,) 0.0\n",
      "(1,) 0.0\n",
      "(2,) 0.0\n",
      "(3,) 0.0\n",
      "(4,) 0.0\n",
      "(5,) 0.0\n",
      "(6,) 0.0\n",
      "(7,) 0.0\n",
      "(8,) 0.0\n",
      "(9,) 0.0\n",
      "(10,) 0.0\n",
      "(11,) 0.0\n",
      "(12,) 0.0\n",
      "(13,) 0.0\n",
      "(14,) 0.0\n",
      "(15,) 0.0\n",
      "(16,) 0.0\n",
      "(17,) 0.0\n",
      "(18,) 0.0\n",
      "(19,) 0.0\n",
      "b1 relative error: 1.65e-24\n",
      "(0,) 0.0\n",
      "(1,) 0.0\n",
      "(2,) 0.0\n",
      "(3,) 0.0\n",
      "(4,) 0.0\n",
      "(5,) 0.0\n",
      "(6,) 0.0\n",
      "(7,) 0.0\n",
      "(8,) 0.0\n",
      "(9,) 0.0\n",
      "(10,) 0.0\n",
      "(11,) 0.0\n",
      "(12,) 0.0\n",
      "(13,) 0.0\n",
      "(14,) 0.0\n",
      "(15,) 0.0\n",
      "(16,) 0.0\n",
      "(17,) 0.0\n",
      "(18,) 0.0\n",
      "(19,) 0.0\n",
      "(20,) 0.0\n",
      "(21,) 0.0\n",
      "(22,) 0.0\n",
      "(23,) 0.0\n",
      "(24,) 0.0\n",
      "(25,) 0.0\n",
      "(26,) 0.0\n",
      "(27,) 0.0\n",
      "(28,) 0.0\n",
      "(29,) 0.0\n",
      "b2 relative error: 2.19e-09\n",
      "(0,) 0.0\n",
      "(1,) 0.052755398360915244\n",
      "(2,) 0.05464065400140327\n",
      "(3,) 0.0\n",
      "(4,) 0.05773973095202222\n",
      "(5,) 0.0\n",
      "(6,) 0.04953513110805829\n",
      "(7,) -0.38420724335352924\n",
      "(8,) 0.051587233018679506\n",
      "(9,) 0.05814773729184707\n",
      "b3 relative error: 1.77e-10\n",
      "(0,) -0.012550244488096494\n",
      "(1,) 0.006126426876917889\n",
      "(2,) -0.008595157519053487\n",
      "(3,) 0.030224947211721084\n",
      "(4,) 0.014311556828516812\n",
      "(5,) 0.018265097034841915\n",
      "(6,) 0.02650295085615539\n",
      "(7,) 0.0173658300628432\n",
      "(8,) -0.032060000432210245\n",
      "(9,) -0.014473552933935705\n",
      "(10,) 0.043478897771009876\n",
      "(11,) -0.006179684541862684\n",
      "(12,) -0.06491357171789502\n",
      "(13,) 0.01581753519275253\n",
      "(14,) 0.042978063863330355\n",
      "(15,) -0.021749182543828734\n",
      "(16,) -0.04358854908126374\n",
      "(17,) 0.0089867332242477\n",
      "(18,) 0.0029382912547504243\n",
      "(19,) -0.03039975879914891\n",
      "beta1 relative error: 1.00e+00\n",
      "(0,) -0.002086657913125123\n",
      "(1,) 0.00558317538867925\n",
      "(2,) 0.004958345867223102\n",
      "(3,) -0.013841348733834023\n",
      "(4,) 0.0015499201921898018\n",
      "(5,) -0.0025769301359446217\n",
      "(6,) -0.01058228371597636\n",
      "(7,) -0.01510209854949096\n",
      "(8,) -0.003711317786425638\n",
      "(9,) -0.002145511679430001\n",
      "(10,) 0.006836499011342311\n",
      "(11,) 0.004901377881338931\n",
      "(12,) -0.02113146071458516\n",
      "(13,) 0.009753486596153493\n",
      "(14,) -0.03339168421767624\n",
      "(15,) 0.00717507946390583\n",
      "(16,) 0.012129295212659484\n",
      "(17,) 0.04642702879920079\n",
      "(18,) -0.0038054104312124078\n",
      "(19,) -0.010195080246688804\n",
      "(20,) -0.013084484340453171\n",
      "(21,) -0.029437271908960835\n",
      "(22,) 5.949951642492123e-05\n",
      "(23,) 0.011919857989539649\n",
      "(24,) 0.022075933792109478\n",
      "(25,) -0.0017058443102513363\n",
      "(26,) -0.00366868242451801\n",
      "(27,) -0.026108920225809126\n",
      "(28,) 0.009481325013993569\n",
      "(29,) 0.00023405468674297933\n",
      "beta2 relative error: 5.47e-08\n",
      "(0,) -0.012463672449669614\n",
      "(1,) 0.006123864926266264\n",
      "(2,) -0.008593144906754446\n",
      "(3,) 0.030161566044739626\n",
      "(4,) 0.014298629391618077\n",
      "(5,) 0.018200419971137194\n",
      "(6,) 0.02641044600792952\n",
      "(7,) 0.017361071558141816\n",
      "(8,) -0.03198610212251651\n",
      "(9,) -0.014472468246040647\n",
      "(10,) 0.04346513389208439\n",
      "(11,) -0.006178567790726674\n",
      "(12,) -0.06356688242448172\n",
      "(13,) 0.015763725702555575\n",
      "(14,) 0.042970075186943284\n",
      "(15,) -0.021742065969831966\n",
      "(16,) -0.043566975982400884\n",
      "(17,) 0.008983310850751991\n",
      "(18,) 0.0029368268261720227\n",
      "(19,) -0.030393334027323245\n",
      "gamma1 relative error: 1.00e+00\n",
      "(0,) -0.0020862360283757653\n",
      "(1,) 0.005582257633918174\n",
      "(2,) 0.004902976780130075\n",
      "(3,) -0.013839841050966582\n",
      "(4,) 0.001549312456106122\n",
      "(5,) -0.0025731759834002332\n",
      "(6,) -0.010580909393098636\n",
      "(7,) -0.015092775873526419\n",
      "(8,) -0.0037093196514348388\n",
      "(9,) -0.0020925088772827394\n",
      "(10,) 0.006830436882765411\n",
      "(11,) 0.0048857224488330075\n",
      "(12,) -0.021124798710303594\n",
      "(13,) 0.00964165240979753\n",
      "(14,) -0.032906554903178176\n",
      "(15,) 0.0071723752714802904\n",
      "(16,) 0.012054941755934577\n",
      "(17,) 0.046407064946407665\n",
      "(18,) -0.003789697311518125\n",
      "(19,) -0.010180819565164256\n",
      "(20,) -0.013076315985571794\n",
      "(21,) -0.029431426185055894\n",
      "(22,) 5.946647618770839e-05\n",
      "(23,) 0.01191813625567306\n",
      "(24,) 0.022010753619738917\n",
      "(25,) -0.001704385388379137\n",
      "(26,) -0.0036439466111204406\n",
      "(27,) -0.02252634923038954\n",
      "(28,) 0.009476564821753186\n",
      "(29,) 0.00023398287751774657\n",
      "gamma2 relative error: 9.92e-08\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "N, D, H1, H2, C = 2, 15, 20, 30, 10\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=(N,))\n",
    "\n",
    "# You should expect losses between 1e-4~1e-10 for W, \n",
    "# losses between 1e-08~1e-10 for b,\n",
    "# and losses between 1e-08~1e-09 for beta and gammas.\n",
    "for reg in [0, 3.14]:\n",
    "  print('Running check with reg = ', reg)\n",
    "  model = FullyConnectedNet([H1, H2], input_dim=D, num_classes=C,\n",
    "                            reg=reg, weight_scale=5e-2, dtype=np.float64,\n",
    "                            normalization='batchnorm')\n",
    "\n",
    "  loss, grads = model.loss(X, y)\n",
    "  print('Initial loss: ', loss)\n",
    "\n",
    "  for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=True, h=1e-5)\n",
    "    print('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))\n",
    "  if reg == 0: print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batchnorm for deep networks\n",
    "Run the following to train a six-layer network on a subset of 1000 training examples both with and without batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "# Try training a very deep net with batchnorm\n",
    "hidden_dims = [100, 100, 100, 100, 100]\n",
    "\n",
    "num_train = 1000\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "weight_scale = 2e-2\n",
    "bn_model = FullyConnectedNet(hidden_dims, weight_scale=weight_scale, normalization='batchnorm')\n",
    "model = FullyConnectedNet(hidden_dims, weight_scale=weight_scale, normalization=None)\n",
    "\n",
    "print('Solver with batch norm:')\n",
    "bn_solver = Solver(bn_model, small_data,\n",
    "                num_epochs=10, batch_size=50,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True,print_every=20)\n",
    "bn_solver.train()\n",
    "\n",
    "print('\\nSolver without batch norm:')\n",
    "solver = Solver(model, small_data,\n",
    "                num_epochs=10, batch_size=50,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=20)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following to visualize the results from two networks trained above. You should find that using batch normalization helps the network to converge much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_training_history(title, label, baseline, bn_solvers, plot_fn, bl_marker='.', bn_marker='.', labels=None):\n",
    "    \"\"\"utility function for plotting training history\"\"\"\n",
    "    plt.title(title)\n",
    "    plt.xlabel(label)\n",
    "    bn_plots = [plot_fn(bn_solver) for bn_solver in bn_solvers]\n",
    "    bl_plot = plot_fn(baseline)\n",
    "    num_bn = len(bn_plots)\n",
    "    for i in range(num_bn):\n",
    "        label='with_norm'\n",
    "        if labels is not None:\n",
    "            label += str(labels[i])\n",
    "        plt.plot(bn_plots[i], bn_marker, label=label)\n",
    "    label='baseline'\n",
    "    if labels is not None:\n",
    "        label += str(labels[0])\n",
    "    plt.plot(bl_plot, bl_marker, label=label)\n",
    "    plt.legend(loc='lower center', ncol=num_bn+1) \n",
    "\n",
    "    \n",
    "plt.subplot(3, 1, 1)\n",
    "plot_training_history('Training loss','Iteration', solver, [bn_solver], \\\n",
    "                      lambda x: x.loss_history, bl_marker='o', bn_marker='o')\n",
    "plt.subplot(3, 1, 2)\n",
    "plot_training_history('Training accuracy','Epoch', solver, [bn_solver], \\\n",
    "                      lambda x: x.train_acc_history, bl_marker='-o', bn_marker='-o')\n",
    "plt.subplot(3, 1, 3)\n",
    "plot_training_history('Validation accuracy','Epoch', solver, [bn_solver], \\\n",
    "                      lambda x: x.val_acc_history, bl_marker='-o', bn_marker='-o')\n",
    "\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch normalization and initialization\n",
    "We will now run a small experiment to study the interaction of batch normalization and weight initialization.\n",
    "\n",
    "The first cell will train 8-layer networks both with and without batch normalization using different scales for weight initialization. The second layer will plot training accuracy, validation set accuracy, and training loss as a function of the weight initialization scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "# Try training a very deep net with batchnorm\n",
    "hidden_dims = [50, 50, 50, 50, 50, 50, 50]\n",
    "num_train = 1000\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "bn_solvers_ws = {}\n",
    "solvers_ws = {}\n",
    "weight_scales = np.logspace(-4, 0, num=20)\n",
    "for i, weight_scale in enumerate(weight_scales):\n",
    "  print('Running weight scale %d / %d' % (i + 1, len(weight_scales)))\n",
    "  bn_model = FullyConnectedNet(hidden_dims, weight_scale=weight_scale, normalization='batchnorm')\n",
    "  model = FullyConnectedNet(hidden_dims, weight_scale=weight_scale, normalization=None)\n",
    "\n",
    "  bn_solver = Solver(bn_model, small_data,\n",
    "                  num_epochs=10, batch_size=50,\n",
    "                  update_rule='adam',\n",
    "                  optim_config={\n",
    "                    'learning_rate': 1e-3,\n",
    "                  },\n",
    "                  verbose=False, print_every=200)\n",
    "  bn_solver.train()\n",
    "  bn_solvers_ws[weight_scale] = bn_solver\n",
    "\n",
    "  solver = Solver(model, small_data,\n",
    "                  num_epochs=10, batch_size=50,\n",
    "                  update_rule='adam',\n",
    "                  optim_config={\n",
    "                    'learning_rate': 1e-3,\n",
    "                  },\n",
    "                  verbose=False, print_every=200)\n",
    "  solver.train()\n",
    "  solvers_ws[weight_scale] = solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot results of weight scale experiment\n",
    "best_train_accs, bn_best_train_accs = [], []\n",
    "best_val_accs, bn_best_val_accs = [], []\n",
    "final_train_loss, bn_final_train_loss = [], []\n",
    "\n",
    "for ws in weight_scales:\n",
    "  best_train_accs.append(max(solvers_ws[ws].train_acc_history))\n",
    "  bn_best_train_accs.append(max(bn_solvers_ws[ws].train_acc_history))\n",
    "  \n",
    "  best_val_accs.append(max(solvers_ws[ws].val_acc_history))\n",
    "  bn_best_val_accs.append(max(bn_solvers_ws[ws].val_acc_history))\n",
    "  \n",
    "  final_train_loss.append(np.mean(solvers_ws[ws].loss_history[-100:]))\n",
    "  bn_final_train_loss.append(np.mean(bn_solvers_ws[ws].loss_history[-100:]))\n",
    "  \n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Best val accuracy vs weight initialization scale')\n",
    "plt.xlabel('Weight initialization scale')\n",
    "plt.ylabel('Best val accuracy')\n",
    "plt.semilogx(weight_scales, best_val_accs, '-o', label='baseline')\n",
    "plt.semilogx(weight_scales, bn_best_val_accs, '-o', label='batchnorm')\n",
    "plt.legend(ncol=2, loc='lower right')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Best train accuracy vs weight initialization scale')\n",
    "plt.xlabel('Weight initialization scale')\n",
    "plt.ylabel('Best training accuracy')\n",
    "plt.semilogx(weight_scales, best_train_accs, '-o', label='baseline')\n",
    "plt.semilogx(weight_scales, bn_best_train_accs, '-o', label='batchnorm')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Final training loss vs weight initialization scale')\n",
    "plt.xlabel('Weight initialization scale')\n",
    "plt.ylabel('Final training loss')\n",
    "plt.semilogx(weight_scales, final_train_loss, '-o', label='baseline')\n",
    "plt.semilogx(weight_scales, bn_final_train_loss, '-o', label='batchnorm')\n",
    "plt.legend()\n",
    "plt.gca().set_ylim(1.0, 3.5)\n",
    "\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "## Inline Question 1:\n",
    "Describe the results of this experiment. How does the scale of weight initialization affect models with/without batch normalization differently, and why?\n",
    "\n",
    "## Answer:\n",
    "[FILL THIS IN]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch normalization and batch size\n",
    "We will now run a small experiment to study the interaction of batch normalization and batch size.\n",
    "\n",
    "The first cell will train 6-layer networks both with and without batch normalization using different batch sizes. The second layer will plot training accuracy and validation set accuracy over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [],
   "source": [
    "def run_batchsize_experiments(normalization_mode):\n",
    "    np.random.seed(231)\n",
    "    # Try training a very deep net with batchnorm\n",
    "    hidden_dims = [100, 100, 100, 100, 100]\n",
    "    num_train = 1000\n",
    "    small_data = {\n",
    "      'X_train': data['X_train'][:num_train],\n",
    "      'y_train': data['y_train'][:num_train],\n",
    "      'X_val': data['X_val'],\n",
    "      'y_val': data['y_val'],\n",
    "    }\n",
    "    n_epochs=10\n",
    "    weight_scale = 2e-2\n",
    "    batch_sizes = [5,10,50]\n",
    "    lr = 10**(-3.5)\n",
    "    solver_bsize = batch_sizes[0]\n",
    "\n",
    "    print('No normalization: batch size = ',solver_bsize)\n",
    "    model = FullyConnectedNet(hidden_dims, weight_scale=weight_scale, normalization=None)\n",
    "    solver = Solver(model, small_data,\n",
    "                    num_epochs=n_epochs, batch_size=solver_bsize,\n",
    "                    update_rule='adam',\n",
    "                    optim_config={\n",
    "                      'learning_rate': lr,\n",
    "                    },\n",
    "                    verbose=False)\n",
    "    solver.train()\n",
    "    \n",
    "    bn_solvers = []\n",
    "    for i in range(len(batch_sizes)):\n",
    "        b_size=batch_sizes[i]\n",
    "        print('Normalization: batch size = ',b_size)\n",
    "        bn_model = FullyConnectedNet(hidden_dims, weight_scale=weight_scale, normalization=normalization_mode)\n",
    "        bn_solver = Solver(bn_model, small_data,\n",
    "                        num_epochs=n_epochs, batch_size=b_size,\n",
    "                        update_rule='adam',\n",
    "                        optim_config={\n",
    "                          'learning_rate': lr,\n",
    "                        },\n",
    "                        verbose=False)\n",
    "        bn_solver.train()\n",
    "        bn_solvers.append(bn_solver)\n",
    "        \n",
    "    return bn_solvers, solver, batch_sizes\n",
    "\n",
    "batch_sizes = [5,10,50]\n",
    "bn_solvers_bsize, solver_bsize, batch_sizes = run_batchsize_experiments('batchnorm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plot_training_history('Training accuracy (Batch Normalization)','Epoch', solver_bsize, bn_solvers_bsize, \\\n",
    "                      lambda x: x.train_acc_history, bl_marker='-^', bn_marker='-o', labels=batch_sizes)\n",
    "plt.subplot(2, 1, 2)\n",
    "plot_training_history('Validation accuracy (Batch Normalization)','Epoch', solver_bsize, bn_solvers_bsize, \\\n",
    "                      lambda x: x.val_acc_history, bl_marker='-^', bn_marker='-o', labels=batch_sizes)\n",
    "\n",
    "plt.gcf().set_size_inches(15, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "## Inline Question 2:\n",
    "Describe the results of this experiment. What does this imply about the relationship between batch normalization and batch size? Why is this relationship observed?\n",
    "\n",
    "## Answer:\n",
    "[FILL THIS IN]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Normalization\n",
    "Batch normalization has proved to be effective in making networks easier to train, but the dependency on batch size makes it less useful in complex networks which have a cap on the input batch size due to hardware limitations. \n",
    "\n",
    "Several alternatives to batch normalization have been proposed to mitigate this problem; one such technique is Layer Normalization [2]. Instead of normalizing over the batch, we normalize over the features. In other words, when using Layer Normalization, each feature vector corresponding to a single datapoint is normalized based on the sum of all terms within that feature vector.\n",
    "\n",
    "[2] [Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. \"Layer Normalization.\" stat 1050 (2016): 21.](https://arxiv.org/pdf/1607.06450.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "## Inline Question 3:\n",
    "Which of these data preprocessing steps is analogous to batch normalization, and which is analogous to layer normalization?\n",
    "\n",
    "1. Scaling each image in the dataset, so that the RGB channels for each row of pixels within an image sums up to 1.\n",
    "2. Scaling each image in the dataset, so that the RGB channels for all pixels within an image sums up to 1.  \n",
    "3. Subtracting the mean image of the dataset from each image in the dataset.\n",
    "4. Setting all RGB values to either 0 or 1 depending on a given threshold.\n",
    "\n",
    "## Answer:\n",
    "[FILL THIS IN]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Normalization: Implementation\n",
    "\n",
    "Now you'll implement layer normalization. This step should be relatively straightforward, as conceptually the implementation is almost identical to that of batch normalization. One significant difference though is that for layer normalization, we do not keep track of the moving moments, and the testing phase is identical to the training phase, where the mean and variance are directly calculated per datapoint.\n",
    "\n",
    "Here's what you need to do:\n",
    "\n",
    "* In `cs231n/layers.py`, implement the forward pass for layer normalization in the function `layernorm_backward`. \n",
    "\n",
    "Run the cell below to check your results.\n",
    "* In `cs231n/layers.py`, implement the backward pass for layer normalization in the function `layernorm_backward`. \n",
    "\n",
    "Run the second cell below to check your results.\n",
    "* Modify `cs231n/classifiers/fc_net.py` to add layer normalization to the `FullyConnectedNet`. When the `normalization` flag is set to `\"layernorm\"` in the constructor, you should insert a layer normalization layer before each ReLU nonlinearity. \n",
    "\n",
    "Run the third cell below to run the batch size experiment on layer normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the training-time forward pass by checking means and variances\n",
    "# of features both before and after layer normalization   \n",
    "\n",
    "# Simulate the forward pass for a two-layer network\n",
    "np.random.seed(231)\n",
    "N, D1, D2, D3 =4, 50, 60, 3\n",
    "X = np.random.randn(N, D1)\n",
    "W1 = np.random.randn(D1, D2)\n",
    "W2 = np.random.randn(D2, D3)\n",
    "a = np.maximum(0, X.dot(W1)).dot(W2)\n",
    "\n",
    "print('Before layer normalization:')\n",
    "print_mean_std(a,axis=1)\n",
    "\n",
    "gamma = np.ones(D3)\n",
    "beta = np.zeros(D3)\n",
    "# Means should be close to zero and stds close to one\n",
    "print('After layer normalization (gamma=1, beta=0)')\n",
    "a_norm, _ = layernorm_forward(a, gamma, beta, {'mode': 'train'})\n",
    "print_mean_std(a_norm,axis=1)\n",
    "\n",
    "gamma = np.asarray([3.0,3.0,3.0])\n",
    "beta = np.asarray([5.0,5.0,5.0])\n",
    "# Now means should be close to beta and stds close to gamma\n",
    "print('After layer normalization (gamma=', gamma, ', beta=', beta, ')')\n",
    "a_norm, _ = layernorm_forward(a, gamma, beta, {'mode': 'train'})\n",
    "print_mean_std(a_norm,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient check batchnorm backward pass\n",
    "np.random.seed(231)\n",
    "N, D = 4, 5\n",
    "x = 5 * np.random.randn(N, D) + 12\n",
    "gamma = np.random.randn(D)\n",
    "beta = np.random.randn(D)\n",
    "dout = np.random.randn(N, D)\n",
    "\n",
    "ln_param = {}\n",
    "fx = lambda x: layernorm_forward(x, gamma, beta, ln_param)[0]\n",
    "fg = lambda a: layernorm_forward(x, a, beta, ln_param)[0]\n",
    "fb = lambda b: layernorm_forward(x, gamma, b, ln_param)[0]\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dout)\n",
    "da_num = eval_numerical_gradient_array(fg, gamma.copy(), dout)\n",
    "db_num = eval_numerical_gradient_array(fb, beta.copy(), dout)\n",
    "\n",
    "_, cache = layernorm_forward(x, gamma, beta, ln_param)\n",
    "dx, dgamma, dbeta = layernorm_backward(dout, cache)\n",
    "\n",
    "#You should expect to see relative errors between 1e-12 and 1e-8\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dgamma error: ', rel_error(da_num, dgamma))\n",
    "print('dbeta error: ', rel_error(db_num, dbeta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Normalization and batch size\n",
    "\n",
    "We will now run the previous batch size experiment with layer normalization instead of batch normalization. Compared to the previous experiment, you should see a markedly smaller influence of batch size on the training history!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_solvers_bsize, solver_bsize, batch_sizes = run_batchsize_experiments('layernorm')\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plot_training_history('Training accuracy (Layer Normalization)','Epoch', solver_bsize, ln_solvers_bsize, \\\n",
    "                      lambda x: x.train_acc_history, bl_marker='-^', bn_marker='-o', labels=batch_sizes)\n",
    "plt.subplot(2, 1, 2)\n",
    "plot_training_history('Validation accuracy (Layer Normalization)','Epoch', solver_bsize, ln_solvers_bsize, \\\n",
    "                      lambda x: x.val_acc_history, bl_marker='-^', bn_marker='-o', labels=batch_sizes)\n",
    "\n",
    "plt.gcf().set_size_inches(15, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "## Inline Question 4:\n",
    "When is layer normalization likely to not work well, and why?\n",
    "\n",
    "1. Using it in a very deep network\n",
    "2. Having a very small dimension of features\n",
    "3. Having a high regularization term\n",
    "\n",
    "\n",
    "## Answer:\n",
    "[FILL THIS IN]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
